Title,Description,PublishedAt,URL,Content
New teaching technologies help train tomorrow's top talent,IBM is partnering with 20 academic institutions to bring specialized tech and training opportunities directly to students.,2022-12-20T17:39:56Z,https://www.businessinsider.com/sc/new-teaching-technologies-help-train-tomorrows-top-talent,By Lydia Logan VP of Global Education and Workforce Development IBM The benefits of experiential learning have been touted for years. We know that immersive active learning helps students apply and retain knowledge at remarkable rates. And while we see cuttingedge technologies cropping up each day in business and entertainment there can be a lag when it comes to the classroom. Why is this a problem The disconnect between technologies used for life and learning contributes to the skills shortage. In softwarerelated fields alone there are more than 1. 2 million US job vacancies. American cybersecurity jobs suffer from more than 700000 vacancies. As we face a historic skills shortage across industries and particularly in STEM Im inspired by programs that offer a fresh approach to skilling our future colleagues and leaders. Experiential programs like hackathons and accessible technologies like virtual reality are creating more opportunities to deliver richer learning to more students. This is key for many STEM professions like cybersecurity analysts which require problemsolving and collaboration. One example of new teaching technologies is in IBMs work with Historically Black Colleges and Universities HBCUs. We are collaborating with 20 HBCUs to bring new technical training opportunities to students and cocreate cybersecurity training centers. Faculty and students have free access to IBM SkillsBuild coursework lectures certifications cloudbased software and professional development. Within these centers we also hold immersive Capture the Flag simulations. These are not the hideandseek games of our childhood but they do require mental gymnastics to find hypothetical cybercriminals. Conceptually its similar to Escape Rooms where teams parse clues to solve puzzles. For Capture the Flag experiences IBM volunteers provide encouragement and instruction in real time. Darryl Terrell a computer science major at Xavier University of Louisiana recently participated in a Capture the Flag cybersecurity training exercise using IBM Security Software to log track and analyze his findings. While these exercises are for advanced students other courses offered by cybersecurity training centers appeal to students from other majors potentially sparking interest in STEM careers. For instance Dr. Robert Owor executive director of Albany State Universitys Center for Innovation and Emerging Technologies is using IBMs curricula from his schools cybersecurity training center to expose noncomputerscience majors to cybersecurity. Were seeing more and more examples of how new technologies are cultivating the next generation of STEM leaders. From early pilots of virtual reality teaching to innovation challenges students are benefitting from access to cuttingedge technologies and multidisciplinary collaboration. Throughout 2022 we expanded our work at IBM SkillsBuild with an emphasis on partnerships between academia and employers across the public and private sectors. Through our work with the Specialisterne Foundation the US Department of Veterans Affairs and the Hispanic Heritage Foundation among many others we are reaching more learners than ever before. In 2023 were excited to explore new experiential learning technologies and help tackle the skills shortage. This post was created by IBM with Insider Studios.
How technology helps a research-intensive medical school secure grants and attract top scientists,Scientists at the Albert Einstein College of Medicine have made major contributions to biomedical research with the support of its partners at IBM.,2022-12-22T17:42:16Z,https://www.businessinsider.com/sc/technology-helps-albert-einstein-college-of-medicine-attract-top-scientists,By Dave McDonnell global solutions leader IBM Storage For more than 60 years the diverse faculty and staff of the Albert Einstein College of Medicine have set the standard for excellence in medical and graduate education and patientcentered clinical care. Scientists have made major contributions to biomedical research that have enhanced human health in areas such as developmental brain research neuroscience cardiac disease and more. During 2021 Einstein received more than 185 million in funding from the National Institutes of Health NIH. Part of NIHs criteria for bestowing grants is how applicants adhere to NIH FAIR guiding principles for research data stewardship findability accessibility interoperability and reusability which have become a cornerstone of research in the life sciences industry. Biomedical research generates enormous data sets because it includes so many files representing the building blocks of life such as elements atoms molecules amino acids DNA genomes and proteins. Meeting researchers demanding data storage requirements Einstein partners with IBM to help meet the NIH standards and manage these huge data sets. Its highperformance computing environment includes the efficient IBM Elastic Storage System ESS which simplifies storage management and eliminates data silos as well as IBM Spectrum Scale software to help manage and secure billions of objects per backup server. The IBM storage infrastructure solution easily supports the demanding requirements of Einsteins large research community. A leadingedge infrastructure helps us attract top research talent said Shailesh Shenoy assistant dean for Einstein Information Technology. Saving money while going green Einstein counts on IBM ESS to reduce inefficiency and acquisition costs by consolidating storage requirements from the edge to the core data center. IBM Spectrum Scale software features an autotiering feature that moves less frequently used data to IBM Tape which only powers up when it is accessed. Spectrum Scales tiering technology has saved us millions of dollars added Shenoy. Nothing can compete with the price point shelf life or density of IBM Tape. Furthermore the tiering contributes to our sustainability initiatives because tape storage only consumes power during reads or writes. Increasing NIH FAIR data maturity The college also employs a multisite backup and disaster recovery strategy to safeguard its research workloads and ensure availability. In fact Einstein recently added another data center on a different power grid to progress further in the NIH FAIR Data Maturity Model as set forth by the Research Data Alliance. Having this data center allows Einstein to continue operations and have protected data even if all three of its Bronx computing sites shut down. This is yet another competitive differentiator for the college contributing to its ability to access government funding for research. Because it deals with highly regulated healthcare data Einstein added IBM Data Guardium Protection to automate compliance auditing and reporting and monitor user activity. Having auditable results increases the confidence in the Einstein scientific process. Research papers can be published faster which also contributes to earning more grant dollars Shenoy continued. Collaborating with the right partners Einstein has realized the importance of collaborating with the right partners to support its breakthrough research IBM and its partner DST have listened to us understood our needs and collaborated with us to evolve and continuously improve our data management discipline. Together we have solved problems and addressed priorities for the past five years. Whats next for Einstein Our next breakthroughs and discoveries remain to be seen concluded Shenoy. But one thing is certain well be moving ahead with the IBMDST team our true partners and technical advisors. Learn more about how you can leverage a leadingedge technology infrastructure. This post was created by IBM with Insider Studios.
How analytics and AI can help you build a better customer experience,"With the help of advanced technology, you can improve customer engagement and retention.",2022-12-23T18:21:37Z,https://www.businessinsider.com/sc/how-analytics-and-ai-can-help-you-build-a-better-customer-experience,Exceptional customer experience is not just an option for businesses in todays digital marketits a necessity. If consumers and business clients find it difficult to place orders get timely help find what theyre looking for or complete some other transaction with a company they might very well switch to a competitor that excels at customer experience. Organizations are fortunate today that technology tools such as advanced analytics and artificial intelligence AI are available to help them deliver enhanced customer experience. But they need to prioritize deploying these capabilitiesand using them correctlyto see any real benefit. Many companies have accelerated their digital transformation efforts for the past few years which has required they put a greater emphasis on customer experience says Matthew Candy global managing partner IBM iX customer and experience transformation at IBM Consulting. Consumer expectations continue to remain high and get higher each and every day he said. And we take experiences that weve had in one industry and those become the benchmark for what we expect in every industry. If I have an amazing experience with my bank and its digital platform and application when I interact with my utilities company I expect the same thing. This notion of customer experience is the thing that creates competitive advantage for companies. Leveraging analytics AI and other nextgeneration technologies can help organizations provide significant differentiation between themselves and their competitors Candy says. They can facilitate a rich profile of a customer based on previous interactions with the individual to determine the customers preferences and to add a much higher level of personalization. And its not just delivering personalized experiences and recommendations but contextually relevant ones Candy says based on the customers situation at the particular point in time. Letting data be the guide Companies in various industries could see benefits from investing in analytics to improve customer experience. For example auto makers could work with IBM Consulting to reimagine customers digital experiences at the first touchpointthe websiteand through the entire customer journey. Using analytics tools based in the cloud an auto maker could anticipate drivers needs and preferences potentially deepening customers connection and loyalty to a brand in part by making it easy for customers to interact with the company. Similarly banks can work with IBM Consulting to improve customer experiences and build loyalty by improving the digital experience. For example simple customer service inquiries can be handled by pairing a customer relationship management platform with IBM Watson chatbots. Once call agents are no longer burdened with responding to those less complex transactions they are free to provide more highvalue interactions with customers equipped with the right tools and data to make informed recommendations and build customer relationships. In a variety of industries companies would be empowered to make business and customerexperience decisions based on data rather than assumptions and through data can see holistic customer journeys and understand how consumers digitally interact with the company. These insights help the company continuously optimize whats working and eliminate what isnt. If I have an amazing experience with my bank and its digital platform and application when I interact with my utilities company I expect the same thing. This notion of customer experience is the thing that creates competitive advantage for companies. Building better customer experiences Candy says there are several best practices organizations should consider to help develop successful customer experience strategies utilizing data analytics and AI tools. One is to employ a designled approach and ensure the design is holistic. That means really getting inside the heads of the users and what theyre thinking feeling saying and doing Candy says. But the design doesnt just focus on the individual and the individuals needs but on business needs and the broader cultural concerns. The key is to use design as a way to get to better customer experiences and to have a continuous design process using data and AI. A second practice Candy recommends is having efficient data connections and use the right data to orchestrate better experiences. Many organizations have lots of data silos and different data sets that are all disjointed Candy said. They need to be able to find a way to bring together those internal and external data sources to build a single understanding of an individual. They must be able to have that joinedup view of data in order to drive insights from it and then put those insights back into the experiences to create better outcomes. Another good practice is to focus on trust and transparency regarding customer data and how AI is used. We need to make sure that we put trust at the heart of everything that were doing Candy said. IBM has published a set of trust and transparency principles around the use of AI and AI ethics. These include The purpose of AI is to augment human intelligence data and insights belong to their creator and new technology including AI systems must be transparent and explainable. Candy also recommends using natural language to take friction out of interactions between customers and chat bots. With natural language conversations that help guide customers through processes they will be less likely to need additional help from a human representative. Finally organizations need to reach outside of their own domains and think about the ecosystem in which they operate in order to get to the outcomes theyre looking for. That means looking for the right types of partners to help provide the best experiences and create better outcomes for the customer Candy said. Learn more about how IBM can help your organization drive a more effective customer experience. This post was created by IBM with Insider Studios.
Industries can get ahead of quantum's future decryption potential right now,Organizations are securing data and infrastructure for the quantum era.,2022-12-22T20:52:54Z,https://www.businessinsider.com/sc/industries-can-get-ahead-of-quantums-future-decryption-potential,By Scott Crowder Vice President IBM Quantum Adoption and Business Development Quantum computers are maturing quickly. And we see their rapid development as an important opportunity to potentially solve business problems that could revolutionize fields from medicine to finance. But this rapid development also brings risk Future quantum computers could crack the encryption schemes that safeguard valuable data like health records and financial data. As we work to bring about quantum computers that deliver practical advantages over todays computers we also must ensure that we continue to protect sensitive systems and data. One immediate concern Harvestnow hacklater attacks where sensitive encrypted data is stolen today for decryption using future quantum computers. This is especially critical for governments and highly regulated industries like finance healthcare and telco. In fact 83 of organizations have experienced more than one data breach in their lifetime according to IBMs 2022 Cost of a Data Breach Report. The good news is that quantumsafe cryptography capable of protecting this information exists today. And government and industry are taking notice. In May the White House released a memorandum laying out the administrations plan for securing critical systems against potential quantum threats. In July the National Institute of Standards and Technology NIST announced four quantumsafe algorithms for postquantum cryptographic standardization which they expect to finalize by 2024. Three of these algorithms were developed by IBM scientists in collaboration with industry and academic partners. And last month the US government issued directions on migrating to quantumsafe cryptography to its agencies. In September telecommunications industry organization GSMA formed a PostQuantum Telco Network Taskforce which IBM and Vodafone joined as initial members to help define processes to protect telcos from this quantum future. The World Economic Forum recently estimated that more than 20 billion digital devices will need to be either upgraded or replaced in the next 1020 years to support these new forms of quantumsafe encrypted communication. To help speed up the understanding and prioritization of what data to protect first IBM recently demonstrated the first Cryptography Bill of Materials. Like the Software Bill of Materials concept from software supply chains IBMs CBOM simplifies the cryptography inventory assessment across software services and infrastructure to identify needed cryptographic components. Moving to quantumsafe cryptography Cryptographic standards rely on problems easy for a computer to check but hard to solve. For example classical computers have a hard time factoring large numbers but can easily check that two prime numbers multiply together to result in some large number. So modern encryption methods often use large numbers as codes such that their prime factors form a key. However in 1994 mathematician Peter Shor developed an algorithm that could quickly factor large prime numbers. His namesake algorithm showed a way to crack these codes with faulttolerant quantum computers. Todays quantum computers arent yet capable of using Shors algorithm to factor the numbers used today but that could change as quantum computers advance in scale quality and speed. With quantum advantage on the horizon business leaders should prepare for how they could benefit. But they should also understand the risk of future faulttolerant quantum computers and explore quantumsafe cryptography to protect their data and systems. We may not know exactly when it will be possible to breach todays encryption but one thing is clear Any data that falls into the wrong hands before an organization transitions to quantumsafe cryptography should be considered lost. And computer systems that need to operate securely without major modifications over time like the computers in cars or embedded in satellites will need to be quantumsafe. Can you afford to wait Learn more about the importance of quantumsafe cryptography in the digital economy. This post was created by IBM with Insider Studios.
Citizen's new Wear OS smartwatches aim to score your alertness using AI,"Citizen has unveiled its second-generation CZ Smart smartwatch based on Wear OS 3, which uses NASA's tech to assess your level of alertness, or lack thereof.",2023-01-04T19:15:28Z,https://www.androidcentral.com/wearables/citizen-announces-new-cz-smart-model-at-ces-2023,Citizens new Wear OS smartwatch taps NASA tech to score your alertness The new CZ Smart lineup relies on IBM Watson and NASAs method for gauging how tired or alert you are. Update Jan 5 150 pm ET The new Citizen CZ Smart lineup is now available for preorder via Amazon opens in new tab. What you need to know Citizen has introduced its secondgeneration CZ Smart smartwatch running on Wear OS 3. The new model is designed to tell you how tired or alert you are based on a NASAinspired assessment method along with IBM Watsons models. It is powered by Qualcomms Snapdragon Wear 4100 and promises more than 24 hours of battery life. At CES 2023 watch company Citizen announced its latest lineup of smartwatch based on Wear OS 3 featuring an AI that measures the wearers level of alertness or fatigue using NASAs technology and IBM Watsons neural networks. The new CZ Smart model is built to determine your chronotype your bodys inclination to sleep at a specific time by collecting and analyzing sleep data over the course of seven to 10 days. This information is displayed on the CZ Smart YouQ app and relies on models developed within the IBM Watson Studio workspace. You can take brief gamified tests on a daily basis so the app can generate Alert Scores. The test is inspired by NASAs Psychomotor Vigilance Task Test a method used to assess an astronauts mental acuity. The goal is to help you boost alertness and ease fatigue by providing personalized advice based on your chronotype according to Citizen. By utilizing a dynamic recognition model to match wearers to their chronotype the CZ Smart YouQ application recommends highly personalized Power Fixes suggested actions to help the wearer mitigate the effects of fatigue improve alertness and promote the building of better habits readying the wearer to meet whatever the day may bring the company said in a press release opens in new tab. Samsung developed something similar for the Galaxy Watch 4 series. Its sleep coaching program tracks your sleep patterns for seven days and assigns you an animal cartoon representing a certain type of sleep. However this feature is exclusive only to the latest CZ Smart lineup. If you own Citizens firstgeneration smartwatches youre out of luck because the YouQ app is not backwardscompatible. The new smartwatches are available in 44mm Sport and 41mm Casual models. They sport a 1. 3inch AMOLED display. The watch is powered by Qualcomms Snapdragon Wear 4100 chip paired with 1GB of RAM and 8GB of storage. Connectivity features include Bluetooth WiFi builtin GPS and NFC. Like many of the best Android smartwatches it includes a heart rate sensor altimeter accelerometer SP02 ambient light sensor and other usual sensors. However it doesnt support Google Assistant or any other voice assistants despite it running Wear OS 3. The latest CZ Smart models will be up for grabs in the United States beginning in March with UK Canada and Mexico to follow suit. The Casual model retails for a base price of 350 and the Sport model for 375. Android Central Newsletter Get the best of Android Central in in your inbox every day Jay Bonggolto always keeps a nose for news. He has been writing about consumer tech and apps for as long as he can remember and he has used a variety of Android phones since falling in love with Jelly Bean. Send him a direct message via Twitter or LinkedIn. Android Central Newsletter Get the best of Android Central in in your inbox every day Thank you for signing up to Android Central. You will receive a verification email shortly. There was a problem. Please refresh the page and try again.
Brand Watch: 2023 will be a year that separates the bona fide from ... - Reuters,"Predictions of the future often come to naught. In the 1930s, British economist John Maynard Keynes famously promised we’d all soon be working 15-hour weeks. In 1959, IBM forecast that the new-fangled photocopier might sell “5,000, at most”. More recently, El…",2023-01-11T11:18:00Z,https://www.reuters.com/business/sustainable-business/brand-watch-2023-will-be-year-that-separates-bona-fide-bogus-sustainability-2023-01-11/,Brand Watch 2023 will be a year that separates the bona fide from the bogus on sustainability pledges January 10 Predictions of the future often come to naught. In the 1930s British economist John Maynard Keynes famously promised wed all soon be working 15hour weeks. In 1959 IBM forecast that the newfangled photocopier might sell 5000 at most. More recently Elon Musk has been predicting every year since 2014 that Tesla will become selfdriving next year it hasnt yet due to regulatory issues according to the car marker. Even so the following three bets on the year ahead are save for the onset of Armageddon a dead cert. First brands will continue insisting that they are taking their social and environmental responsibilities seriously second critics will point out the flaws in their performance and argue not enough is being done and third both parties will legitimately to an extent believe themselves correct to the detriment of progress. To kick off with brands. Such is the slew of public commitments from net zero by 2050 to naturepositive that it is almost impossible for big companies to row back now. True external pressures might complicate progress doubledigit inflation and economic recession might well cause some fair weather friends to slow up warns Adam Carrel a partner at EY Climate Change and Sustainability Services and coauthor of a recent white paper Enough. But those genuinely committed to the cause know the issues are too big and the threats too imminent to renege entirely note the subtitle of Carrels paper A review of corporate sustainability in a world running out of time. Though the economic winds may be the fundamental drivers of brand engagement remain unchanged. Reputation above all remains king. The difference of being seen as eco or ethical is only set to grow. Take ethical fashion. If the market analysts prove right demand for sustainable labels is set to grow by 10. 33 in the year ahead total value 8. 25 billion. Nor are the advantages just on the high street. Sustainable investment is growing at a compound annual growth rate of 12. 9 according to PwC. Thats a lot of capital that needs a home. To turn to the critics. Will there be targets missed in the year ahead Yes. Will brands employ advertising that pushes the good and neglects the bad such as HSBCs now infamous climate change doesnt do borders campaign Yes again. Both are as regrettable as they are inevitable. Regarding targets if they do what they are designed to do ie stretch companies to the limits then falling short will always be a risk. CocaCola and PepsiCo are among a slew of big consumer brands that pledge to make their plastic packaging 100 recyclable by 2025 for instance a target that looks increasingly unlikely to be reached. But is it better they strive and reach only 80 or set a target of 40 and succeed in reaching it Sustainability folk will say the first lawyers and PR advisers might well urge the second. One way around the dilemma is to get smarter about what targets are set and why. Tolerance for plucking numbers from the sky is wearing thin says Rory Sullivan cofounder of sustainability consultancy Chronos. Equally working busily in one area while avoiding the metaphorical and hardertosolve elephant in the room wont wash either. Consider netzero goals. Too many companies shout about reducing their direct Scope 1 and 2 carbon emissions while brushing those of their supply and value chains under the carpet. Consumers and investors he argues are both looking for targets and related data that clarify if and how a brand is making a meaningful and positive difference to society. To that end the year ahead requires more targets that focus on performancerelated impacts rather than processdriven outcomes. The former provide absolute improvements while those of the latter are only ever relative Sullivan states citing the findings of a recent research project he coled into the retail sector. Disingenuous advertising is less easy to defend. Some might argue that such is the nature of the beast but todays circumspect hyperinformed consumers dont buy it. For George Ames director of Forster Communications the fact that shoppers and regulators have an increasingly watchful eye can only be a good thing. It keeps the pressure on to be proportionate and accurate with communications he argues. It also reminds brands that companies sustainability messaging needs to be rooted in realistic plans and corresponding actions. The danger is that we dawdle into 2023 with both groups doggedly continuing as before ie with brands arguing they are trying and critics countering that the scale and pace of their efforts are insufficient. If so brands that currently take an active stance on sustainability might well go quiet a trend known as green hushing while those in the shadows will likely stay where they are. Giles Gibbons founder of the consulting firm Good Business sums up the dilemma succinctly We must allow business to be aspirational to risk committing to the unknown rather than sitting at the edge if we critics stop companies pushing the envelope we are going to have less ambition and less change. So are there grounds for hope One potentially significant change is the development of clearer markers on what good looks like. Lee Green senior director at the industryled Sustainable Apparel Coalition points to the European Commissions muchawaited substantiating green claims proposal. Expected to be published imminently the release date was initially scheduled for late 2022 the initiative aims to provide brands with a common language underpinned by the EUs product environmental footprint methodology for communicating the eco credentials of their goods. Having agreed rules should help sort the bona fide from the bogus. Similar moves are afoot in the more regulated field of communications. The gradual convergence of reporting norms should make the information that brands provide to financial markets increasingly consistent says Gerbrand Haverkamp executive director at the World Benchmarking Alliance. He points in particular to initiatives such as the International Sustainability Standards Board and the Corporate Sustainability Reporting Directive. Again the more harmonised the rules the tighter the parameters for how sustainability performance is communicated. All the same brands hoping for a smoother ride in 2023 may be disappointed. New demands on companies are appearing along with new actors demanding them. Biodiversity is an apt example. Under the Global Biodiversity Framework agreed at COP15 in December for instance brands will be expected to demonstrate how they are contributing to the initiatives goals on biodiversity. Likewise under the EUs proposed Corporate Sustainability Due Diligence Directive scheduled for a final vote in the European Parliament in May greater attention will be turned to the supply chains on big brands particularly on environmental and human rights issues. Patience on all sides is wearing thin for talk without action. In a telling sign of the times British beer brand BrewDog recently found itself ejected from the B Corporation community whose UK members now top 1000 after reports of a toxic work culture. The 2023 wish list of EYs Carrel meanwhile is for greenwashing to become classified as fraud not just unethical PR. The overarching solution he maintains is to decouple sustainability from subjectivity and bring it back to a factbased alignment with realworld outcomes. Unfortunately brands revel in subjectivity. Its the essence of the intangible value that not only sustains them but also gives them their unique power to influence and inspire. The best brands stand for something that goes beyond the physical Tshirt on the rack say or the hatchback on the forecourt. That something is difficult to quantify in hard facts and figures. Yet as far as sustainability is concerned demonstrate it they must. Quite how they do so hopefully 2023 will show.
How AI Is helping to reduce landfill waste,One organization is bringing innovation to waste management using intelligent automation.,2022-12-22T18:06:15Z,https://www.businessinsider.com/sc/how-ai-is-helping-to-reduce-landfill-waste,By Stefano Innocenti Sedili Senior Account Technical Leader at IBM Imagine a world no longer habitable by humans where only heaps of trash remain as our legacy. We havent reached that scenario yet but we are producing incomprehensible amounts of waste at a faster rate all the time. In the European Union for example the weight of annual municipal solid waste exceeded 230 million metric tons in 2020 the last year of reported data having increased for seven consecutive years. Thats more than 1. 3 billion pounds of trash every day. In an ideal world the obvious solution might be to simply stop producing so much waste to begin with. This is easier said than done. But circular economy models can provide smart examples and accessible starting points for how we can work toward avoiding a trashy future so to speak. A circular economy is a model of production and consumption that can benefit businesses people and the environment by getting the most use and least waste out of the stuff we use. For an example of a perfect circular economy look to nature. A plant grows nearby wildlife feeds on it and both eventually die and nourish the flora and fauna that once nourished them. Humans tend to engage in a more linear maketakewaste process. We make things buy and use them then trash them. If only things like plastic bags diapers and old computers degraded as fast as autumn leaves and nourished the soil in the process. Let a circular economy mindset drive innovation Circular economy activities can potentially yield significant advantages for business and government such as improving the security of the raw materials supply stimulating innovation boosting economic growth and creating jobs. In a recent study by the IBM Institute for Business Value chief supply chain officers surveyed identified several specific actions they plan to take over the next three years in pursuit of their circular economy goals To move toward circularity organizations can automate workflows with environmental impact and innovation in mind. Waste management companies in particular have an opportunity to minimize landfill waste using artificial intelligence and automation technologies. How to bring innovation to waste management and potentially influence an entire industry As a provider of electricity water cycle management and heating services and as Italys largest waste management and recycling company Hera S. p. A is on the front lines of the urgency to reduce waste and minimize environmental damage. Where traditional recycling practices may be one arc in the cycle of reuse Hera offers integrated solutions that help complete the circle. With plastics for example it not only recovers waste but also incorporates it into the production of highquality new products that are themselves recyclable. Today in our territories most of the waste is recovered... only a small portion ends up burnt but this is burnt in wastetoenergy plants producing new energy said Andrea Bonetti manager of IT architecture at Hera. But the recovery process depends on quickly finding and separating reusable material from tons of refuse. It was for this process that Hera decided to explore how intelligent automation could improve efficiency and help channel more material to new use. Thus began an innovative project led by Heras Environmental Innovation Department managed by Milena Zappoli. Evaluating the potential of AI for waste sorting Hera personnel analyze waste manually. As trucks unload at the entrance to the plants and the trash is pushed toward conveyors spotters watch for recoverable materials including plastics aluminum and paper and help direct downstream sorting. Its an onerous job especially at scale 1400 spotters work at 89 plants where 6. 3 million tons of waste is treated every year. Hera envisioned capturing video of incoming trash and using AI to recognize characteristics of items and materials that would qualify them for recovery and reuse. This could have a decisive impact on the costs of recovery and disposal activities which is the focus of the circular economy Bonetti said. The Hera and IBM Garage teams quickly recognized that the plantsat the end of the collection processwere not the right place to capture video. The teams wanted information on the quality of the material at the source. So they identified a better vantage point upstream. By mounting cameras on trash trucks they could video the smaller amounts of material falling out of bins. Its still an extremely rapid passage of images said Zappoli. But the study of these images has allowed us to identify significant patterns for the qualitative evaluation of the waste during the collection process not inside the plant which could improve the time and cost of the transformation process. The results have been promising as Hera gradually scales out the technology. At the beginning says Zappoli we had two vehicles equipped for the project. Now we have seven and the performance of the model has significantly improved in a few months of training. For plastics the precision with which the model correctly detects the quality has gone from 40 to 65. For paper the information useful for recognizing the quality show levels of error of about 10. These rates when deployed at scale would mean significant quantities of plastics and paper rerouted. Zappoli and team continue to work on refining the models to maximize detection rates. The Hera team also hopes to correlate wastequality data with collection locations helping the company develop targeted information campaigns to help people better differentiate between waste items. The experience with IBM Garage has allowed us to activate a particularly innovative solution in the field of waste collection selection and recovery Zappoli said. The project is positioned along the entire operational supply chain and can be a valid support to increase efficiency but above all it can affect the improvement of the quality of separate collection and therefore the maximization of recyclable waste making full use of the efforts made by the Hera Group in the circular economy. Create automation that propels innovation. This post was created by IBM with Insider Studios.
A hacker's tips on how to spot a phishing attack,Organizations can take these cybersecurity measures to ensure they don't fall prey to an attack.,2022-12-23T16:33:08Z,https://www.businessinsider.com/sc/a-hackers-tips-on-how-to-spot-a-phishing-attack,When it comes to cybersecurity attacks phishing continues to be effective for hackers and costly for organizations. The 2022 IBM XForce Threat Intelligence Index research showed that phishing is the way attackers are getting into organizations 41 of the time. And a successful phish for an attacker comes with a hefty price tag for victims 4. 91 million in fact according to the Cost of Data Breach 2022 conducted by Ponemon Institute and sponsored analyzed and published by IBM Security. And the phishing attempts are only getting more personalized and harder to spot. So how can you tell if an email is legitimate or if it poses a threat Stephanie Snow Carruthers Chief People Hacker for IBM XForce Red is a social engineer and works with clients to find potential weaknesses and exploit them before The best thing people can do is slow down. Take the time to really evaluate what you are seeing. Ask yourself Do I actually know this sender Does this request make senseStephanie Snow Carruthers How can individual employees protect themselves against phishing attempts The best thing people can do is slow down. Take the time to really evaluate what you are seeing Snow said. Ask yourself Do I actually know this sender Does this request make sense She adds that knowing when to ask for help is crucial. Better safe than sorry so if youre unsure ask your manager andor the IT team for help qualifying the email. We need to work together to stay safe. Finally Snow cautions against how popularized but outdated advice can be detrimental. I still see advice out there telling people to look for bad grammar and spelling errors. Sophisticated attackers arent always making those same mistakes any longer. Dustin Heywood Chief Architect of XForce STSM says that the most important defense is to take the time to verify anything someone tells you. For example say you get an email about a package to be picked up. You can copy the tracking number without clicking on it go directly to the shipping companys website and enter in the tracking number on a form. Developing the habit of always verifying information makes you much less susceptible to attack. There is not a single business or IT problem that cant wait for the information to be verified prior to acting Heywood said. How organizations can protect themselves against phishing attempts According to Matthew DeFir Executive Consultant XForce Incident Response here are a few things organizations can do to help protect an environment that is experiencing a phishing attack or receives a lot of phish Be sure your employees know what to look for when it comes to suspicious emails by regularly offering phishing awareness programs. Turn on external tagging so users can see when an email came from outside their organizations. This will signal to employees that they should proceed with additional caution given that the email originated externally. Audit email mailbox rules for new rule creations. Implement multifactor authentication for mailboxes. If a universal MFA is not possible focus on high value users like those in the Csuite or accounts payable who are most vulnerable to Business Email Compromise BEC attacks. Install security proxies which can audit andor prevent traffic to malicious domains and IPs based on reputation or categorization of that domain. DeFir recommends that clients if they can use a security proxy to block uncategorized domains. Most legitimate business traffic would be over legit categorized business domains. Developing the habit of always verifying information makes you much less susceptible to attack. There is not a single business or IT problem that cant wait for the information to be verified prior to acting. Dustin Heywood Chief Architect of XForce STSM Continuous threats require continuous preparedness The days of left and right of boom where we were thinking about how to prepare for and recover from threats have passed explains Laurance Dine Global Partner XForce Incident Response. Cybersecurity attacks are no longer a oneoff challenge for organizations. They present an ongoing risk with realworld consequences. We need to meet this continuous cycle of threats with a continuous cycle of preparedness remediation and recovery Dine said. I cannot emphasize enough how important it is for organizations to not only develop an incident response plan but to test it regularly. According to the Cost of a Data Breach Report 2022 organizations with an incident response team that tested their incident response plan versus those who did not saved on average 2. 66M in data breach costs. The threat landscape is continually evolving says Dine. So it makes sense that our cybersecurity strategies should continually evolve as well. Learn more about incident response planning and threat intelligence here. This post was created by IBM with Insider Studios.
Patched Windows Bug Was Actually a Dangerous Wormable Code-Execution Vulnerability,"Ars Technica reports on a dangerously ""wormable"" Windows vulnerability that allowed attackers to execute malicious code with no authentication required — a vulnerability that was present ""in a much broader range of network protocols, giving attackers more fle…",2022-12-25T19:36:00Z,https://tech.slashdot.org/story/22/12/25/1934243/patched-windows-bug-was-actually-a-dangerous-wormable-code-execution-vulnerability,Patched Windows Bug Was Actually a Dangerous Wormable CodeExecution Vulnerability arstechnica. com 20 Ars Technicareports on a dangerously wormable Windows vulnerability that allowed attackers to execute malicious code with no authentication required a vulnerability that was present in a much broader range of network protocols giving attackers more flexibility than they had when exploiting the older vulnerability. Microsoft fixed CVE202237958 in September during its monthly Patch Tuesday rollout of security fixes. At the time however Microsoft researchers believed the vulnerability allowed only the disclosure of potentially sensitive information. As such Microsoft gave the vulnerability a designation of important. In the routine course of analyzing vulnerabilities after theyre patched IBM security researcher Valentina Palmiotti discovered it allowed for remote code execution in much the way EternalBlue did the flaw used to detonate WannaCry. Last week Microsoft revised the designation to critical and gave it a severity rating of 8. 1 the same given to EternalBlue.... One potentially mitigating factor is that a patch for CVE202237958 has been available for three months. EternalBlue by contrast was initially exploited by the NSA as a zeroday. The NSAs highly weaponized exploit was then released into the wild by a mysterious group calling itself Shadow Brokers. The leak one of the worst in the history of the NSA gave hackers around the world access to a potent nationstategrade exploit. Palmiotti said theres reason for optimism but also for risk While EternalBlue was an 0Day luckily this is an NDay with a 3 month patching lead time said Palmiotti. One potentially mitigating factor is that a patch for CVE202237958 has been available for three months. EternalBlue by contrast was initially exploited by the NSA as a zeroday. The NSAs highly weaponized exploit was then released into the wild by a mysterious group calling itself Shadow Brokers. The leak one of the worst in the history of the NSA gave hackers around the world access to a potent nationstategrade exploit. Palmiotti said theres reason for optimism but also for risk While EternalBlue was an 0Day luckily this is an NDay with a 3 month patching lead time said Palmiotti. Theres still some risk Palmiotti tells Ars Technica. As weve seen with other major vulnerabilities over the years such as MS17010 which was exploited with EternalBlue some organizations have been slow deploying patches for several months or lack an accurate inventory of systems exposed to the internet and miss patching systems altogether. Thanks to Slashdot reader joshuark for sharing the article.
When is a PC not a PC? The PC-98,"I’ve covered PC compatibility in the past, and tried to explain how just having an x86 CPU and running DOS does not necessarily make your machine compatible with an IBM PC. At the time, this …",2023-01-07T18:54:24Z,https://scalibq.wordpress.com/2023/01/07/when-is-a-pc-not-a-pc-the-pc-98/,Ive covered PC compatibility in the past and tried to explain how just having an x86 CPU and running DOS does not necessarily make your machine compatible with an IBM PC. At the time this was mainly about the IBM PCjr and its clone the Tandy 1000 which is still relatively close to a regular PC. As such you could create software that would run on both IBM PCs and compatibles and on the PCjrTandy with custom code paths for specific functionality such as sound and graphics. But pretty much all other DOSx86based machines failed as their hardware was too different and their marketshare was too small for developers to bother adding support. In fact the main reason that the Tandy 1000 existed at all is because the earlier Tandy 2000 was falling into the trap of not being compatible enough. The Tandy 1000 may actually not be a very good example as Tandy tried to make it nearly 100 compatible fixing the main reason why the IBM PCjr also failed. So later Tandy 1000 models were more or less a best of both worlds nearly 100 compatible with IBM PC but also offering the enhanced graphics and sound capabilities of the PCjr. Meanwhile in Japan In Japan however things took a different turn. The Japanese do not just use the Latin alphabet that is used on all Western machines including the IBM PC. The Japanese language uses more complex glyphs. They have multiple systems such as kanji katakana and hiragana. To display these in a comfortably readable form you need a highresolution display. Also where Latin letters encode sounds a kanji glyph encodes a word or part of a word. This means that your glyph alphabet contains over 50000 characters a lot more than the maximum of 256 characters in your usual 8bit Western character set. So the Japanese market had very specific requirements that PCs could not fulfill in the early DOS days. You couldnt just replace the character ROM on your PC and make it display Japanese text IBM did later develop the 5550 and the JX a derivative of the PCjr specifically for the Japanese market and later they developed the DOSV variant which added support for Japanese text to their PS2 line using standard VGA hardware which by now had caught up in terms of resolution. Instead Japanese companies jumped into the niche of developing business machines for the home market. Most notably NEC. In 1981 they introduced the PC8800 series an 8bit home computer based on a Z80 CPU and BASIC. In 1982 the PC9800 series followed a more highend 16bit businessoriented personal computer based on an 8086 CPU and MSDOS. These families of machines became known as PC88 and PC98 respectively Note that the PC name here is not a reference to IBM as NEC had already released the PC8000 series in 1979. In this article I will be looking at the PC98 specifically. So lets start by doing that literally here are some pictures to give an impression of what these machines looked like. They look very much like IBM PC clones dont they For more machines specs and background info I suggest this NEC Retro site. How compatible is it It has an 8086 CPU an NEC 765 floppy controller an 8237 DMA controller an 8253 programmable interval timer and two 8259A programmable interrupt controllers. Sounds just like a PC doesnt it okay two PICs sounds more like an AT actually so NEC was ahead of its time here Well it would be if it used the same IO addresses for these devices. But it doesnt. What makes it especially weird is that since it has always been a system with a 16bit bus using an 8086 as opposed to the 8088 in early PCs NEC chose to map any IO registers of 8bit devices either on even addresses only or on odd addresses only so the 16bit bus is seen as two 8bit buses. For example where the first 8259A on a PC is mapped to ports 0x20 and 0x22 the PC98 places it at 0x00 and 0x02 leaving 0x01 as a gap in between. The 8237 DMA controller is actually mapped on address 0x01 0x03 and so on. Another major difference is that the base frequency of the PIT is not 1. 19 MHz like on the PC but depending on the model it can be either 1. 99 MHz or 2. 46 MHz. And like the PCjr and the Tandy 1000EXHX models it has an expansion bus but it is not the ISA bus. The PC98 uses the Cbus. So you cannot use standard expansion cards for IBM PCs in this machine. Clearly the video system isnt compatible with any PC standard either. It does not even use int 10h as the video BIOS. Speaking of BIOS the PC98 BIOS is not compatible with the IBM PC BIOS either. But as said the video system was far superior to the IBM PC at the time. The first version in 1982 already supported 640400 with 8 colours based on NECs own uPD7220 video controller. In 1985 they extended this with a palette of 4096 colours to choose from and an optional 16 colour mode if an extra RAM board was installed. In 1986 the extra RAM became standard on new models and they also added a hardware blitter for block transfers raster operations and bit shifting. Whats also interesting is that they chose to actually use TWO uPD7220 chips in a single machine. One of them is used for text mode the other for bitmapped graphics mode. They each have their own video memory and are used in parallel. So you can actually overlay text and graphics on a single screen. But on the other hand There are two things that we can use to our advantage It runs an NEC PC98 OEM version of MSDOS A lot of the hardware is the same as on the PC So this means that for basic functionality such as file and text IO memory management and such we dont need the BIOS. We can use MSDOS for that which abstracts the machinespecific BIOS stuff away. Also if we write code that uses the 8237 8253 8259A or other similar hardware in most cases we only need to change the IOaddresses they use and adjust for the different PIT frequency and other minor details such as the different cascaded configuration of the two PICs and different IRQs for devices and we can make it work on the PC98. So just like with Tandy and PCjr we can write DOS programs and make them work on PC98. We can even write a single program that can run on both types of systems even though it is a bit more complicated than on TandyPCjr on those you mainly had to avoid using DMA and you should be aware that the keyboard is different so you should only access it via BIOS or have separate routines for the different machines. Challenge accepted I decided to give this a try. I have made my own little SDK of headers and library functions for ASM and C over the years which includes quite a few constants for addressing IO ports or memory areas of all sorts of PC and TandyPCjr hardware I modeled it after the Amiga NDK. I figured I would try a PC98 emulator and port my VGM player over to the PC98 and update the SDK with PC98 support in the process. A convenient emulator is DOSBoxX. It is a fork of DOSBox which adds a PC98 machine among other features and like DOSBox the BIOS and DOS emulation is builtin and you can just mount host directories as drives so you dont have to juggle all sorts of ROMs and disk images to get the system running. If you want a more serious emulator though Neko Project 21W is one of the more compatibleaccurate ones. And indeed you can just use OpenWatcom C to write a DOS application and it will work as the basic runtime only requires DOS interrupts no BIOS or direct hardware access. All the BIOS and direct hardware access is done via my SDK anyway so as long as I write the correct code for PC98 BIOS and addresses I can use any hardware from C or assembly of course. Whats more it turns out to be relatively simple to detect whether you are running on an IBM PCcompatible or a PC98 compatible machine. A trick that is used is to call int 10h with AH0Fh. On an IBM PCcompatible this will return information about the current video mode with AH containing the number of columns. On the PC98 this will not be implemented so after the call the value of AH will be unaffected. Since there is no video mode with 15 columns you can assume that if AH is 0Fh after the call that you are running on a PC98 machine. Anyway before long I had a basic version of my VGM player working on both the IBM PC and the PC98. Its a pretty fun and quirky platform so far. So I might be looking into the graphics chip in the near future. If you also like to play around with DOS and x86 and want to give the PC98 a try here are some good resources you might need to translate as most documentation can only be found in Japanese httpradioc. web. fc2. comcolumnpc98basindexen. htm httpswww. webtech. co. jpcompanydocundocumentedmem
"Psst, automating these 3 parts of your business is the best thing you can do right now","Content provided by IBM and TNW Thanks to the convergence of several trends and changes across different markets and industries, automation is becoming a critical factor in the success of businesses and products. Advances in artificial intelligence, in parall…",2022-12-21T10:23:01Z,https://thenextweb.com/news/automating-3-parts-business-right-now,
"Southwest, still reeling from last week's meltdown, just suffered another system glitch that grounded flights","Southwest pilots announced the weather system outage to passengers, per tweets. It comes a day after the airline said it had made ""solid progress.""",2023-01-04T11:06:59Z,https://www.businessinsider.com/southwest-airlines-weather-system-glitch-grounds-delay-flights-passengers-2023-1,Southwest still reeling from last weeks meltdown just suffered another system glitch that grounded flights Southwest experienced a weather system outage which disrupted flight schedules again. Pilots made announcements while passengers were waiting for the flight some people tweeted. Southwest Airlines was on Tuesday hit by a weather system outage which grounded flights and caused disruption again for passengers. Several people posted on Twitter about their flight delays saying the pilot announced the weather system was down and the plane was unable to take off. One person tweeted that they were sitting on the aircraft for an hour and a half and waiting to depart because of the issue. Southwest apologized in response. Around 140 Southwest flights were canceled on Tuesday while more than 1500 were delayed according to flighttracking site FlightAware. The airline told Insider in a statement on Tuesday that its thirdparty vendor IBM had a brief outage in their service that provides weather data prior to Southwest dispatching flights. Southwest added that it expected minor delays for the remainder of the night. In the statement the company also apologized to passengers for the inconvenience and encouraged customers to check the flight status on its website. Pilots are required to be aware of weather reports and forecasts before a flight commences according to federal regulations. The weather system outage came the same day Southwest said it had made solid progress to resolve passengers problems with luggage reduce flight cancellations and process refund requests. Following a bitter winter storm that swept across parts of the US over the holiday period Southwests flight schedule was heavily impacted for several days. Passengers faced flight cancellations and delays while airports were flooded with missing baggage. Southwest said on December 30 it planned to resume normal operation with minimal disruptions. SMBs can easily upskill their workforce using this effective learning management solution Device deployment hits 1 million for two straight quarters How Paytm Soundbox is fuelling growth Jack Ma the billionaire founder of Alibaba who disappeared from public view in 2020 appears to resurface in Thailand as he prepares to give up control of his company Amazon Great Republic Day Sale best deals on phones iPhone 13 OnePlus Nord 2T 5G Redmi A1 and more Wipro sees FY23 revenue growth at 11. 512 Q3 profit growth beats analyst expectations Rupee falls 4 paise to close at 81. 34 against US dollar 13th Gen Intel Core i913900KS brings unprecedented speed to desktop users Credit expansion will taper down next year if deposits growth doesnt rise Axis Bank MD
Citizen debuts CZ Smart Watch dedicated to wellness,"Citizen has debuted its CZ Smart Watch with its proprietary wellness software that anticipates, learns, and gets smarter with the wearer.",2023-01-04T13:05:00Z,https://venturebeat.com/games/citizen-debuts-cz-smart-watch-dedicated-to-wellness/,Watchmaker Citizen has debuted its CZ Smart Watch with its proprietary wellness software that anticipates learns and gets smarter with the wearer. CZ Smart YouQ forecasts 24 hours ahead to help the wearer extend peaks and curb drops in alertness. It leverages NASA scientific research and AI models built with IBM Watson studio to offer personalized actions to optimize wearer wellness. Citizen made the announcement at the CES 2023 tech trade show in Las Vegas. Its interesting to see a 100yearold watch company pushing into wearables like a startup. The CZ Smart YouQ software helps the wearer understand and anticipate patterns of fatigue and alertness. It offers customized insights and personalized strategies to build better habits to maximize a wearers daily potential. CZ Smart watches combine watch design purposeful function and innovative technology in a gamechanging wearable device the company said. Using research on biofeedback and neural networks developed within the IBM Watson Studio workspace CZ Smart YouQ can learn and understand the wearers chronotype an individuals preferred timing of sleep and wake within seven to ten days by processing their sleep data and Alert Scores. It deepens that understanding over time. Alert Scores are generated when a wearer takes a customdesigned Alert Monitor test a consumerfacing iteration of NASAs Psychomotor Vigilance Task Test PVT originally developed to determine the mental acuity of astronauts. The CZ Smart YouQ Alert Monitor was designed based on NASAs PVT test and utilizing research from leading science and academic experts at NASAs Ames Research Center Fatigue Countermeasures Laboratory. The Alert Monitor tests are brief gamified and can be taken daily to measure the wearers alertness. The watch gathers personal data points captured with the watch including Alert Scores chronotype sleep patterns activity and heartrate monitoring. Then CZ Smart YouQ quantitatively analyzes and learns about the wearers unique characterization rhythms and habits to enhance personalization. By utilizing a dynamic recognition model to match wearers to their chronotype the CZ Smart YouQ application recommends highly personalized Power Fixes suggested actions to help the wearer mitigate the effects of fatigue improve alertness and promote the building of better habits readying the wearer to meet whatever the day may bring. Over time aggregating wearer data will enable CZ Smart YouQ to cater to wearers more personally not just in understanding them and their relationship to chronotypes but also in understanding the effectiveness of certain Power Fixes for each person. The latest CZ Smart watch is a gamechanging product that brings Citzenss legacy of watchmaking together with bestinclass research and technology of NASA and IBM directly to wearers wrists said Jeffrey Cohen President at Citizen Watch America in a statement. Coupled with the proprietary CZ Smart YouQ application this smartwatch is a revolution in wearable wellness. The YouQ Software is available exclusively on the second generation of CZ Smart watches. Styles include a sport model available with silicone leather and stainlesssteel bracelet straps and a casual model in mesh bracelet stainless steel links and silicone straps. All Citizen CZ Smart watches offer downloadable customizable dials and a range of interchangeable bracelet mesh leather and silicone straps for practicality and style preference. Citizen also highlighted a new secondgeneration hybrid smartwatch at CES 2023 which will launch to consumers in the second half of 2023 with the YouQ wellness software implemented in due course date to be confirmed. It uses a Qualcomm Snapdragon Wear4100 processor. Citizen launched the first generation of CZ Smart watches in November 2020 with the brands firstever touchscreen smartwatch followed by a hybrid model in fall 2021. The latest generation of CZ Smart watches with the proprietary CZ Smart YouQ application will be available in the U. S. at www. citizenwatch. com starting in March 2023. GamesBeats creed when covering the game industry is where passion meets business. What does this mean We want to tell you how the news matters to you not just as a decisionmaker at a game studio but also as a fan of games. Whether you read our articles listen to our podcasts or watch our videos GamesBeat will help you learn about the industry and enjoy engaging with it. Discover our Briefings.
Escalating concerns for AI in 2023 and what can be done,"AI developments in 2023 come with mounting concerns. Find out what might go wrong, what's going right, and how to apply the right solutions.",2023-01-03T18:00:00Z,https://venturebeat.com/ai/escalating-concerns-for-ai-in-2023-and-what-can-be-done/,When people think of artificial intelligence AI what comes to mind is a cadre of robots uniting as sentient beings to overthrow their masters. Of course while this is still far out of the realm of possibility throughout 2022 AI has still woven its way into the daily lives of consumers. It arrives in the form of good recommendation engines when theyre shopping online automatically recommending solutions for customer service questions from the knowledge base and suggestions on how to fix grammar when writing an email. This trend follows what was established last year. According to McKinseys The State of AI in 2021 report 57 of companies in emerging economies had adopted some form of AI up from 45 in 2020. In 2022 an IBM survey found that though AI adoption is gradual four out of five companies plan to leverage the technology at some point soon. In 2023 I expect the industry to further embrace AI as a means to continue software evolution. Users will witness the technology providing contextual understanding of written and spoken language helping arrive at decisions faster and with better accuracy and telling the bigger picture story behind disparate data points in more useful and applicable ways. Event Intelligent Security Summit OnDemand Learn the critical role of AI ML in cybersecurity and industry specific case studies. Watch ondemand sessions today. Privacy a central topic These exciting developments are not without mounting concerns. I expect privacy or lack thereof to remain a central topic of discussion and fear among consumers in fact I believe that if the metaverse doesnt take off it will be due to privacy concerns. Pieces of AI also need to be trained and current processes for doing so carry a high likelihood of introducing biases such as misunderstanding spoken language or skewing data points. Simultaneously the media and international governance have not caught up to where AI currently sits and is headed in 2023. Despite all these problems AI is going to move the needle for enterprises in 2023 and in turn they will capitalize by improving experiences or processes continuing on what Ive been seeing AI do for the last handful of years. Doing so will require a sharp focus on what might go wrong whats currently going right and how to swiftly apply forwardthinking solutions. Heres more information on all three and how companies can kick off the process. AI fully enters the mainstream As mentioned before mainstream adoption of AI is on the way. Devices apps and experience platforms are all likely to come equipped with AI right from the getgo. No longer will consumers be able to optin which will accelerate and heighten concerns about AI that exist in the mainstream already. Privacy reigns supreme in this regard. Given how many public data breaches have occurred over the last few years including those at LinkedIn MailChimp and Twitch consumers are understandably wary of giving out personal information to tech companies. Its unfortunate because consumers have proven that they are willing to share some personal information if it leads to a better experience. In fact according to the 2022 Global Data Privacy report by Global Data and Marketing Alliance 49 of consumers are comfortable with providing personal data and 53 believe doing so is of paramount importance for maintaining the modern tech landscape. One of the central issues is that there isnt any consensus on what best practices look like across the industry its tough to garner data if the concept of ethical collection is fluid. AI isnt necessarily new but the technology is still in its nascent stages and governance has not yet matured to the point where there exists any consistency across companies. For example California has enacted strong privacy laws that protect consumers the California Consumer Privacy Act CCPA yet at this moment they remain one of the only states to take direct action. Some states such as Utah and Colorado have legislation in the pipeline. Full transparency a must To prepare for the inevitability of AIfirst technology companies could demonstrate full transparency by providing easy access to their privacy policies or if none exist compose them as soon as possible and make them readily available to view on the companys website. Privacy policy composition is still driven by 1998 guidance from the Federal Trade Commission FTC which stipulates that policies contain these five elements NoticeAwareness Consumers must be made aware that their information is going to be collected how that information will be used and who will be receiving it ChoiceConsent Consumers have the opportunity to optin or optout of data collection and to what degree AccessParticipation Consumers can view their data at any point and implement tweaks as needed IntegritySecurity Consumers are provided with the steps a company is taking to ensure their data remains secure and accurate while obscuring irrelevant personal details EnforcementRedress Finally consumers must understand how troubleshooting will occur and what consequences exist for poor handling of data. Granular language while generally frowned upon in communicating with a nontechsavvy audience is welcome in this instance as consumers with a full understanding of how their data gets used are more likely to share bits and pieces. Biases in AI must be eliminated Biases are often invisible even if their effects are pronounced which means their elimination is difficult to guarantee. And despite its advanced state AI in 2023 remains just as prone to biases as its human counterparts. Sometimes this technology has trouble parsing accents perhaps it fails to present a balanced set of data points at times it could eschew accessibility and disenfranchise a cohort of users. Biases are usually introduced early in the process. AI needs to be trained and many companies opt either for purchasing synthetic data from thirdparty vendors which is prone to distinct biases or having it comb the general internet for contextual clues. However no one is regulating or monitoring the world wide web its worldwide after all for biases and theyre likely to creep into an AI platforms foundation. Financial investments in AI arent likely to trivialize anytime soon so in 2023 its of particular importance to establish processes and best practices to scrub as many biases known or unknown as quickly as possible. Human safeguards One of the most effective safeguards against bias is keeping humans between the data collection and processing phases of AI training. For example here at Zoho some employees join AI in combing through publicly available data to first scrub any trace of personally identifiable data not only to protect these individuals but to ensure only crucial pieces of information make it through. Then the data is further distilled to include only whats relevant. For example an AI system that will be reaching out to pregnant women does not require behavior data on women who are not pregnant and its unreasonable to expect AI to make this distinction right away. An important thing to remember about bias is that it remains an evolving concept and a moving target particularly as access to data improves. Thats why its essential for companies to ensure that they are routinely scanning for new information and accordingly updating their criteria for bias. If the company has been treating its data like code with proper tags version control access control and coherent data branches this process can be completed more swiftly and effectively. The media narrative remains relentless At the center of the above two issues sits the media which is prone to repeat and reemphasize two conflicting narratives. On the one hand the media reports that AI is a marvelous piece of technology with the potential to revolutionize our daily lives in both obvious and unseen ways. On the other though they continue to insinuate that AI technology is one step away from taking peoples jobs and declaring itself supreme overlord of Earth. As AI technology becomes more ubiquitous in 2023 expect the current medias approach to remain mostly the same. Its reasonable to anticipate a slight increase in stories about data breaches though as more access to AI will lead to a greater possibility that a consumer could find themselves affected. This trend could exacerbate a bit of a catch22 AI cannot truly improve without increased adoption yet adoption numbers are likely to stagnate due to lags in technology improvement. Companies can pave their own trail away from the medias lowgrade fearmongering by embracing directtoconsumer D2C marketing. The strongest way to subvert media narratives is for companies to build one of their own through wordofmouth. Once consumers get their hands on the technology itself they can better understand its wow factor and potential to save them countless amounts of time accomplishing basic tasks or tasks they hadnt even considered could be tackled by AI. This marketing tack also affords companies a chance to get ahead of news stories by accentuating privacy policies and comprehensive protocols in the event of an issue. Customers guide the future of AI Best of all a strong customer base in 2023 opens lines of communication between vendor and client. Direct detailed feedback drives relevant comprehensive updates to AI. Together companies and their customers can forge an AIdriven future that pushes the technology envelope while remaining responsible with safe secure and unbiased data collection. Just dont tell the robots. Ramprakash Ram Ramamoorthy is head of labs and AI research at Zoho. DataDecisionMakers Welcome to the VentureBeat community DataDecisionMakers is where experts including the technical people doing data work can share datarelated insights and innovation. If you want to read about cuttingedge ideas and uptodate information best practices and the future of data and data tech join us at DataDecisionMakers. You might even consider contributing an article of your own Read More From DataDecisionMakers
"How organizations can build intelligent, resilient, and sustainable supply chains",Companies can transform their supply chain management with a few simple steps.,2022-12-23T18:15:07Z,https://www.businessinsider.com/sc/how-to-build-intelligent-resilient-and-sustainable-supply-chains,For myriad complex reasons global supply chains have been experiencing significant disruptions for more than two years causing enterprises to move beyond initial stopgap measures and put a greater emphasis on reimagining their supply chain management. This can require new strategies new tools and infrastructure to implement. Aiding companies in this transformation are data analytics artificial intelligence and machine learning technologiesall of which can help businesses build the intelligent predictive resilient and sustainable supply chains they need. Organizations are realizing how vulnerable they are to supply chain issues said Jonathan Wright global managing partner finance supply chain transformation at IBM. In the past the supply chain wasnt really something you needed to know about if it was working well Wright said. Stuff arrived when you needed it. The COVID19 pandemic highlighted the fact that an efficient supply chain is absolutely critical to business success. Supply chains are now critical in terms of driving the top line and also driving bottom line profit. Because having efficient supply chains can be critical to todays digital businesses companies should have greater endtoend realtime visibility of their supply chains Wright says. This requires deploying technology that gathers data from a variety of sources and provides a way to make sense of all the data. Power of digital transformation Data analytics and AI are absolutely key for driving visibility and transparency Wright says. One of the biggest benefits of data analytics and AI within the context of supply chains is decision support. For example having realtime insights about shipping delays because of weather problems or product shortages can help executives make more informed decisions about the steps to take to work around the issues. Historically such decisions have taken weeks or days to make but now with data and AI they often have the information to make the decisions in minutes Wright said. AIbased solutions such as IBMs Watson which provide context from similar supply chain issues that have occurred in the past can combine this insight with new data coming in to help decision makers determine the next steps to take when confronting issues today. Analytics and AI tools work best for managing supply chains when they automate processes that were previously handled manually Wright says. Not only does automation free up people from performing mundane tasks but it can help speed up processes and increase the accuracy and reliability of supply chain data. Companies can also deploy robotics and edge computing technologies to handle the more intensive supply chain tasks such as evaluating power plants or repairing difficulttoreach assets in the field. Effective supply chain management is more important than ever given the great uncertainty of the worldwide market. The previous month or the previous quarter have always been good predictors of whats going to happen in the next month or quarter Wright said. Supply chains have grown incrementally and progressively being very predictable. Now were entering a new world where we have more volatility. Theres more uncertainty than ever and we must now use AI and ML to better understand the drivers behind consumer behavior the real demand signals. Factors that can impact supply chains include economic conditions such as recession and inflation geopolitical events and conflicts and dramatically shifting customer demand. The drive for sustainable sourcing and operations too can affect supply chains. More secure more sustainable In addition to the operational benefits your supply chains can derive from digital transformation a unified data environment that is transparent and serves as a single source of truth can help protect against security vulnerabilities. Moreover using cloudbased applications from established vendors can offer more robust security than traditional onpremises applicationsunknown connections and widespread exception processes are a major challenge for security professionals and reducing them is almost always a net security benefit. Furthermore the ability to simulate changes to the supply chain technology before applying them to the production supply chain provides a valuable opportunity to identify and correct security flaws. And the same technology foundations that are designed to help improve resiliency and security also support sustainability goals. For instance applying AI tools can help optimize metrics such as miles traveled or labor hours needed for a particular shipment. Further realtime visualization can enable manufacturers to associate product expiration dates with intransit orders helping to utilize older stock first and reduce rates of spoilage. Or it can help predict upcoming surges of demand for products allowing a company to ship by more environmentally friendly rail instead of rushed air freight. Strategic initiatives As with any nextgeneration technologies there are different ways to use data analytics and AI. By implementing a few key strategic initiatives organizations can get the most value from these tools to enhance their supply chains. 1. Start small Start with small projects to build competence and a business case for investing in these technologies. Gain some quick wins and momentum and then accelerate Wright said. Its much more important to gain acceptance and demand from business users than it is to push technology on them across endtoend processes. Its really important when implementing new technology that you get momentum and support. Then you can scale fast. 2. The right data Another vital practice is ensuring data accuracy. Youve got to get the data right because were asking the technology thats interpreting the data to inform decisions Wright said. For example Wright explains if a retailer is getting data reporting that certain store shelves are smaller than they actually are its ordering system will order too few products for those shelves and the store will therefore frequently be out of stock on those products. Other issues might include wrong delivery addresses or wrong prioritizations. These things will cause real issues when it comes to automating or trying to get the system to give you decision support Wright said. So data cleanliness is really important. He adds that AI and analytics can actually be helpful tools for spotting anomalies in data. 3. Culture and mindset Another important practice is to create a culture that values the adoption of data analytics and AI and supports change management. Even with automation human beings operate these systems and if the humans have trust in the output then they will use them to make informed decisions Wright said. The way to build the right culture is to have the supply chain management teams support the design testing and implementation of the technology. If your teams are part of that change process they will become advocates of it which will then allow you to get some quick momentum Wright said. Building intelligent resilient and sustainable supply chains 14 June 2022. Find out how IBM can help your organization transform supply chain operations. This post was created by IBM with Insider Studios.
The Citizen CZ Smart YouQ smartwatch uses NASA and IBM technology to ‘predict’ your fitness,"The Citizen CZ Smart YouQ smartwatch uses NASA and IBM technology to ‘predict’ your fitnessDubbed the ‘Smarter Watch’, the CZ Smart doesn’t track you through the day… it anticipates your day in advance. Watchmaking pioneer CITIZEN just revealed its...",2023-01-04T16:07:14Z,https://www.yankodesign.com/2023/01/04/the-citizen-cz-smart-youq-smartwatch-uses-nasa-and-ibm-technology-to-predict-your-fitness/,Dubbed the Smarter Watch the CZ Smart doesnt track you through the day it anticipates your day in advance. Watchmaking pioneer CITIZEN just revealed its latest offering at CES this year the CZ Smart watch the YouQ app designed in partnership with IBM Watson and NASA Ames Research Center. While looking just like any premium watch the nextgen CZ Smarts true functionality is unlocked when combined with the YouQ app that gathers parses and learns from the data provided by the smartwatch. The watch comes in a variety of styles sporting CITIZENs iconic design with a rotating bezel a crown and two pushers sitting beside the circular display and the ability to swap between leather silicone mesh and link variants. The latest CZ Smart watch is a gamechanging product that brings CITIZENs legacy of watchmaking together with bestinclass research and technology of NASA and IBM directly to wearers wrists said Jeffrey Cohen President at CITIZEN Watch America. Coupled with the proprietary CZ Smart YouQ application this smartwatch is a revolution in wearable wellness. The unisex watch comes with a metal body made from 316L stainless steel. Now in its secondgen the first gen was released back in 2020 the watch also comes with the YouQ app that uses machine learning to constantly learn more and more about you so the longer you wear the watch the more personalized its experience gets. The smartwatch sports a 1. 28 AMOLED display that offers high visibility in any time of the day and the battery lasts for 24 hours on a full charge. The watch also comes with a builtin gyroscope altimeter barometer accelerometer heart rate sensor SP02 and an ambient light sensor. It runs the Wear OS by Google but is interoperable with both Android and iOS devices. The CZ Smart YouQ app is perhaps the most impressive bit of tech here. Developed in partnership with IBM and NASA the YouQ app possesses the ability to crunch data in ways that other smartwatches cant. While smartwatches just present diagnostic data like your heart rate sleep quality fitness weather etc the YouQ goes into prognosis actively predicting and giving you actionable insights. It studies your sleep patterns and tells you when to sleep to get the best quality rest tracks your behavior and provides key insights to help you stay more focused and less fatigued and lets you generate Alert Scores to test your mental acuity. Alert Scores are generated when a wearer takes a customdesigned Alert Monitor test a consumerfacing iteration of NASAs Psychomotor Vigilance Task Test PVT originally developed to determine the mental acuity of astronauts. The Citizen CZ Smart 2nd gen watches will be available starting March 2023 on CITIZENs website with a price range of 350 435. The proprietary YouQ application will be available at the same time although its only designed to work with the 2nd gen CZ Smart range of watches and a hybrid series that will launch at a later date.
The APL Programming Language Source Code (2012),"Thousands of programming languages were invented in the first 50 years of the age of computing. Many of them were similar, and many followed a traditional, evolutionary path from their predecessors. What eventually became APL was first a mathematical notation…",2022-12-20T11:31:27Z,https://computerhistory.org/blog/the-apl-programming-language-source-code/,Thousands of programming languages were invented in the first 50 years of the age of computing. Many of them were similar and many followed a traditional evolutionary path from their predecessors. But some revolutionary languages had a slant that differentiated them from their more generalpurpose brethren. LISP was for list processing. SNOBOL was for string manipulation. SIMSCRIPT was for simulation. And APL was for mathematics with an emphasis on array processing. What eventually became APL was first invented by Harvard professor Kenneth E. Iverson in 1957 as a mathematical notation not as a computer programming language. Although other matrixoriented symbol systems existed including the concise tensor notation invented by Einstein they were oriented more towards mathematical analysis and less towards synthesis of algorithms. Iverson who was a student of Howard Aikens taught what became known as Iverson Notation to his Harvard students to explain algorithms. Iverson was hired by IBM in 1960 to work with Adin Falkoff and others on his notation. In his now famous 1962 book A Programming Language 1 he says the notation is for the description of procedurescalled algorithms or programs and that it is a language because it exhibits considerable syntactic structure. But at that point it was just a notation for people to read not a language for programming computers. The book gives many examples of its use both as a descriptive tool such as for documenting the definition of computer instruction sets and as a means for expressing general algorithms such as for sorting and searching. Anticipating resistance to something so novel he says in the preface It is the central thesis of this book that the descriptive and analytical power of an adequate programming language amply repays the considerable effort required for its mastery. Perhaps he was warning that mastering the language wasnt trivial. Perhaps he was also signaling that in his view other notational languages were less than adequate. The team of course soon saw that the notation could be turned into a language for programming computers. That language which was called APL starting in 1966 emphasized array manipulation and used unconventional symbols. It was like no other computer program language that had been invented. APL became popular when IBM introduced APL360 for their System360 mainframe computer. Unlike most other languages at the time APL360 was also a complete interactive programming environment. The programmer sitting at an electromechanical typewriter linked to a timeshared computer could type APL statements and get an immediate response. Programs could be defined debugged run and saved on a computer that was simultaneously being used by dozens of other people. Written entirely in 360 assembly language this version of APL took control of the whole machine. It implemented a complete timesharing operating system in addition to a highlevel language. With the permission of IBM the Computer History Museum is pleased to make available the source code to the 19691972 XM6 version of APL for the System360 for noncommercial use. The text file contains 37567 lines which includes code macros and global definitions. The 90 individual files are separated by. ADD commands. To access this material you must agree to the terms of the license displayed here which permits only noncommercial use and does not give you the right to license it to third parties by posting copies elsewhere on the web. Download APL360 Source Code Jrgen Winkelmann at ETH Zrich has done an amazing job of turning this source code into a runnable system. For more information see MVT for APL Version 2. 00. Iversons book A Programming Language 1 uses a graphical notation that would have been difficult to directly use as a programming language for computers. He considered it an extension of matrix algebra and used common mathematical typographic conventions like subscripts superscripts and distinctions based on the weight or font of characters. Here for example is a program for sorting numbers To linearize the notation for use as a computer programming language typed at a keyboard the APL implementers certainly had to give up the use of labeled arrows for control transfers. But one feature that they were able to retain to some extent was the use of special symbols for primitive functions as illustrated in this program that creates Huffman codes APL uses symbols that are closer to standard mathematics than programming. For example the symbol for division is not. To support the unconventional symbols APL360 used a customdesigned keyboard with special symbols in the upper case. Even so there were more special characters than could fit on the keyboard so some were typed by overstriking two characters. For example the grade up character a primitive operator used for sorting was created by typing shift H then backspace then shift M. There was no room left for both upper and lowercase letters so APL supported only capital letters. For printing programs Iverson and Falkoff got IBM to design a special type ball for their 1050 and 2741 terminals which used the IBM Selectric typewriter mechanism. Now programs could be both typed in and printed. Here for example is the printed version a program from the APL Language manual 2 that computes the mathematical determinant of a matrix APL is a concise highlevel programming language that differs from most others developed in the 1960s in several respects Order of evaluation Expressions in APL are evaluated righttoleft and there is no hierarchy of function precedence. For example typing the expression 243 causes the computer to immediately type the resulting value 14 The value is not as in many other languages that have operator precedence 11. Of course parentheses can be used to group a subexpression to change the evaluation order. The general rule is that the right argument of any function is the value of the expression to its right. Automatic creation of vectors and arrays A higherdimensional structure is automatically created by evaluating an expression that returns it and scalars can be freely mixed. For example A 2 1 2 3 creates the vector 1 2 3 add the scalar 2 to it and creates the variable A to hold the vector whose value is 3 4 5 Variables are never declared they are created automatically and assume the size and shape of whatever expression is assigned to them. A plethora of primitives APL has a rich set of builtin functions and operators that are applied to functions to yield different functions that operate on scalar vectors arrays even higherdimensional objects and combinations of them. For example the expression to sum the numbers in the vector A created above is simply A where is the reduction operator that causes the function to the left to be applied successively to all the elements of the operand to the right. The expression to compute the average of the numbers in A also uses the primitive function to determine how many elements there are in A A A Here are some tables from the 1970 APL360 Users Manual 3 that give a flavor of the power and sophistication of the builtin APL functions and operators. APL encourages you to think differently about programming and to use temporary highdimensional data structures as intermediate values that are then reduced using the powerful primitives. A famous example is the following short but complete program to compute all the prime numbers up to R. TT. TT1R Here is how this expression is evaluated Note that there are no loops in this program. The power of APL expressions means that conditional branches and loops are required far less often than in more traditional programming languages. APL operators can be used in easy ways for all sorts of computations that would usually require loops. For example an expression that computes the number of elements of the vector X that are greater than 100 is X100 It works because X100 returns a bit vector of 0s and 1s showing which elements of X are greater than 100 and adds up all the bits in that vector. But conditional execution and loops are of course sometimes needed. In the light of later developments in structured programming APLs only primitive for control transfer the GO TO LINE x statement is particularly weak. Here is an example of a function that computes the greatest common divisor of its two arguments. The last statement creates a loop by branching to the beginning. In line 2 conditional transfer of control to line 0 causes the function to exit and return the value last assigned to G. To learn more about the 1960s APL language see the APL Language reference manual 2 and Paul Berrys 1969 APL360 Primer 4. The language has of course evolved over the years and more recent versions include control structures such as IFTHENELSE. The first computer implementation of APL notation was a batchoriented language interpreter written in FORTRAN in 1965 for the IBM 7090 mainframe computer by Larry Breed at the IBM Research Center in Yorktown Heights NY and Philip Abrams then a graduate student at Stanford University. The first interactive version was written soon after for the 7093 an experimental 7090 with virtual memory by Larry Breed and Roger Moore. It ran under the TSM timesharing system and was whimsically called IVSYS which rhymes with IBSYS the name for the standard 7090 operating system. In a 2012 email Breed says Another implementation of a subset of the language was done in 1967 for the IBM 1130 minicomputer. The first implementation of APL to get widespread use outside of IBM was for the IBM System360. Called APL360 it went into service first within IBM in November 1966. The notation APL360 since the backslash was the APL expansion operator also had a hidden meaning APL expands the 360. Breed says of the time just before By August 1968 APL360 was available to IBM customers as an unsupported Type III program in IBMs Contributed Program Library 5. The principal implementers were Larry Breed Dick Lathwell and Roger Moore others who had contributed were Adin Falkoff and Luther Woodrum. Because of the dynamic nature of APL variables APL360 was implemented as an interpreter not as a compiler that generated machine code. Programs were stored in an internal form called a codestring that directly corresponded to what the user had typed. The interpreter would then examine the codestring as the program executed and dynamically allocate and reconfigure variables as expressions were evaluated. The first versions of APL360 took control of the entire machine. It was thus a combination operating system file system timesharing monitor command interpreter and programming language. Given the limited main memory user workspaces were swapped out to drum or disk as needed. Performance was impressive which Larry Breed attributes in his clear and succinct description of the implementation 6 to the ability to tailor the operating system to the requirements of the language. APL360 was a conversational language that provided fast response and efficient execution for as many as 50 simultaneous users. Each user had an active workspace that held programs variables and the state of suspended program execution. System commands like LOAD SAVE and COPY maintained the users library of stored workspaces. Other system commands controlled language features for example with ORIGIN the programmer could control whether vectors and arrays are numbered starting with 0 or 1. APL was the first introduction to interactive timesharing for many in the generation of programmers who had suffered through batch programming with punched cards. Even before it was a computer programming language Iverson Notation was useful as a language for documenting algorithms for people. The classic example is the formal definition of the instructionset architecture of the new IBM System360 computer which was published in an article in the IBM Systems Journal by Adin Falkoff Ken Iverson and Ed Sussenguth in 1965 7. But the text provided in the paper is much more than that. It is a linebyline explanation of the formal description which means that it is also a demonstration and explanation of APLs descriptive power. The notation used the graphical style for control transfers that was in Iversons book. Here for example is the description of a memory access operation. It was the transition of APL from a notation for publication into an interactive computer programming language that made it flourish. When the APL360 implementation was available IBM and others stimulated use by producing diverse applications such as these Many of these applications emphasized interactivity which provided a huge productivity increase compared to the batchjob processing more typical at the time. In addition APL allowed applications to be developed much more quickly. In a 2012 email Larry Breed noted The areas in which APL had the greatest penetration were in scientific actuarial statistical and financial applications. For details about the progression of APL in its first 25 years see the special 1991 issue of the IBM System Journal 10 with 12 papers and one essay on the subject. APL was not originally designed as a programming language. As Iverson said With so many terse and unusual symbols APL computer programs like the mathematical notation that inspired it has a conciseness and elegance many find appealing. APL attracts fanatic adherents. Alan Perlis the first recipient of the ACMs Turing Award in 1966 was one Many find the freedom of expression in APL liberating. But APL programs are often cryptic and hard to decode. Some have joked that it is a writeonly language because even the author of a program might have trouble understanding it later. It inspires programming trickery. The challenge of writing an APL oneliner to implement a complete complex algorithm is hard to resist. Here for example are two different APL oneliners that implement versions of John Conways Game of Life life1. 3 41 0 1. 1 0 1. Not for the fainthearted clearly. Dutch computer scientist Edsger Dijkstra said But fans of APL would say that cryptic APL coding is a bad programming style that can be an affliction with any language. APL provides a richer palette for expressing algorithms the argument goes so you can solve harder problems faster and with less irrelevant syntactic clutter. Whatever your view APL and the languages it inspired such as APL2 and J are still an active part of the diverse programming language universe. Kenneth Eugene Iverson was born on December 17 1920 on a farm near Camrose Alberta Canada. He was educated in rural oneroom schools until the end of 9th grade when he dropped out of school because it was the height of the Depression and there was work to do on the family farm. He later said the only purpose of continuing his schooling would have been to become a schoolteacher and that was a profession he decidedly did not want. During the long winter months he studied calculus on his own. He was drafted in 1942 and during his service he took enough correspondence courses to almost complete high school. After the military service he earned a B. A. in both mathematics and physics from Queens University in Kingston Ontario and then an M. A. in physics from Harvard University. In 1954 he completed a PhD under computer pioneer Howard Aiken with a thesis titled Machine Solutions of Linear Differential Equations Applications to a Dynamic Economic Model. After completing his doctorate Iverson joined the Harvard faculty to teach in Aikens new automatic data processing program. He was there for one year as an Instructor and for five years as an Assistant Professor. He became increasingly frustrated with the inadequacy of conventional mathematical notation for expressing algorithms so he began to invent his own. In 1960 Iverson joined the new IBM Research Center in Yorktown Heights New York on the advice of Frederick Brooks who had been one of his teaching fellows at Harvard and was now at IBM. The two collaborated on the continuing development of the new notation. In 1962 Ken published the nowclassic book A Programming Language 1 the title of which gave the name APL to the notation which had up until then been informally called Iversons notation. Iverson continued to work on the development of APL throughout his tenure at IBM. In 1980 he left IBM and returned to Canada to work for I. P. Sharp Associates which had established an APLbased timesharing service. In 1987 he retired from paid employment and turned his full attention to the development of a more modern dialect of APL. APL was successfully being used for commercial purposes but Iverson wanted to develop a new simple executable notation more suitable for teaching which would be available at low cost. The first implementation of this language called J was announced at the APL90 Users Conference. Iversons ability to create such languages came from his sheer enjoyment of language and words recalls his daughter Janet Cramer. He read dictionaries like people read novels. Iverson thought it was important that language both English and mathematics communicate clearly and concisely. With collaborators that included his son Eric Iverson continued to work on the development of J and he continued to publish prolifically. On Saturday October 16 2004 he suffered a stroke while working on a J tutorial and died three days later on October 19 at the age of 83. There are many stories about Ken Iverson. Here are a few
Teensy Twofer of Plug-In Emulated Retro CPUs,[Ted Fried] wrote in with not one but two (2!) new drop-in replacements for widespread old-school CPUs: the Zilog Z80 and the Intel 8088. Both of the “chips” run in cycle-accurate mode as well as i…,2022-12-27T06:00:00Z,https://hackaday.com/2022/12/26/teensy-twofer-of-plug-in-emulated-retro-cpus/,Ted Fried wrote in with not one but two 2 new dropin replacements for widespread oldschool CPUs the Zilog Z80 and the Intel 8088. Both of the chips run in cycleaccurate mode as well as in a super turbo mode which can run so fast that youll need to use the Teensys internal RAM just to keep up. Both of these designs have a hardware and software component. The PCBs basically adapt the pinout of the Teensy to the target CPU with a bunch of 74VLC latches on board to do the voltage level conversion. The rest is a matter of emulating all of the instructions on the Teensy which is more than fast enough to keep up. If this sounds familiar to you its basically the same approach that Ted used last year to bring us his replacement for the 6502 found in the Apple and Commodore 64. Why would you want an emulated CPU when the originals are still available Ted inherited a busted Osborne I an ancient Z80 luggable. By replacing the original Z80 with his emulation he could diagnose the entire system which led him to discover some bad DRAM chips and get the old beast running again. Or maybe you just want to play IBM XT games at insane speeds And it looks like Ted has updated his 6502 emulation to include the undocumented C64 opcodes so if youre into that scene you should be covered as well. If any of this tickles your fancy head over to Teds blog microcore labs and follow along. Although now that hes covered most of the famous retrocomputers we have to ask ourselves what processor is going to be next
Citizen’s new smartwatch uses NASA technology to help you reduce fatigue,Citizen's new smartwatch is expected to go on sale in March.,2023-01-04T15:37:52Z,https://www.androidauthority.com/citizen-smartwatch-ai-3262402/,Links on Android Authority may earn us a commission. Learn more. Citizens new smartwatch uses NASA technology to help you reduce fatigue Citizen has announced that it is launching a new version of the CZ Smart smartwatch. Citizen has created a proprietary app for the watch built with IBM Watson Studio and NASA technology. The watch will go on sale in March 2023. There are plenty of smartwatches that offer wellness features to help with things like fatigue. However Citizens newly announced smartwatch has something going for it that the others dont NASA technology and IBM Watson. At CES Citizen announced that it is launching a new version of its CZ Smart smartwatches. The new smartwatch comes with a unique builtin selfcare advisor AI that works with the companys new proprietary YouQ app. The fascinating thing about this particular wellness app is that it was built with IBM Watson Studio and uses technology from NASA. According to Citizen its app uses IBM Watson to analyze a wearers chronotype an individuals preferred timing of sleep and wake. This is done over a period of seven to 10 days by processing their sleep data and alert scores. The alert scores are handled by a customdesigned alert monitor test that uses a consumer version of NASAs Psychomotor Vigilance Task Test PVT plus test. This test was originally created to determine the mental acuity of astronauts and was designed by the Ames Research Center Fatigue Countermeasures Laboratory. Citizen explains that its alert tests are brief gamified and can be taken daily to measure the wearers alertness. The YouQ app reportedly uses this data to learn your rhythm and habits which allow it to recommend personalized Power Fixes. These Power Fixes are suggestions for actions and activities the users can do to remedy their fatigue improve alertness and build better habits. Citizen says that the YouQ app will only work for secondgeneration CZ smartwatches. So if you own a firstgeneration CZ Smart smartwatch youll be out of luck. The new CZ Smart smartwatch will include a sport model and a casual model. The sports model will come with either silicone or metal bracelet straps while the casual model will come with a mesh bracelet links or silicone straps. If youre interested in picking one up for yourself Citizen didnt provide a price for the gadget. However it expects to start selling the device in March in the US.
What Is SQL and How Does It Work?,"SQL is behind your computer's ability to access database information. Discover SQL, how it works and more in this guide.",2022-12-26T18:00:00Z,https://www.entrepreneur.com/growing-a-business/what-is-sql-and-how-does-it-work/441569,What Is SQL and How Does It Work SQL is behind your computers ability to access database information. Discover SQL how it works and more in this guide. Out of all the programming languages you need to learn in the IT industry SQL is one of the most important. SQL is so integral to modern big data access and organization processes that its never a bad idea to grasp the basics of this language even if you dont work in the IT industry. This article will break down what SQL is how it works and when this language is used for everyday operations. What is SQL SQL stands for structured query language. This core programming language is primarily used to manipulate or communicate with information databases. For example when a computer requests information from a local library SQL facilitates information transfer between that terminal and the librarys database. However SQL is also frequently used by businesses. SQL enables enterprises to access and organize the mountains of data they collect from their customers which is increasingly common and important today. Related Learn How to Manage Data Like a Pro with This SQL Course SQL was created in the 1970s by IBM laboratories. Scientists at IBM created SQL to take advantage of a new database software system called System R. SQL was needed to manage all the data stored in System R. SQL was initially called Sequel which is where the language got its acronym and spoken name. SQL was then updated in 1979 by Relational Software a company that later became Oracle. Oracle changed SQL into Oracle V2 a modified version of SQL. Today SQL is still widely used around the world for a variety of purposes. To be more specific SQL allows users to Execute precise queries against a database or collection of data as a relational database. Retrieve or update records and data in a database. Insert new records into a database. Delete old records in the database. Make new databases or create new tables in the same database for further optimization and organization. Make stored procedures and views for a database. Set user permissions for procedures views tables and database data sets. In other words SQL allows users to accurately access and manipulate their data sets in an efficient streamlined way. SQL servers and relational database management systems or RDMS are available from organizations like Microsoft in their Microsoft SQL Server MS SQL. Its a standard of the American National Standards Institute ANSI and the International Organization for Standardization ISO. What is SQL used for At its core SQL is used to access and manipulate database information. For example businesses may use SQL to modify add to remove or otherwise organize data stored in private databases. In addition businesses can use SQL programs to create and alter data tables an essential part of data analysis and understanding. Note that a database is any tool used to collect and organize dense information in these circumstances. Databases for example can store customer information transaction information and much more. SQL is often needed for other programs or programming languages to interface with databases stored on remote or onsite servers. Python Javascript or some other standard language can interact with an SQL database which uses its own data manipulation language DMLdata definition language DDL. An SQL protocol can access the data before retrieving it and translating it into an output or format that Python can understandrender to an end user. Overall SQL is essential for the following Accessing or removing data. Editing data in databases. Assisting with data analytics. Connecting different programs or programming languages with databases. Given its versatility and importance SQL is one of the best programming languages to learn. If you want to join the IT industry at any point becoming fluent in SQL standards will bolster your resume and career prospects. Related Transform Data Into GameChanging Insights with This SQL Training Major elements of SQL The SQL language has several vital elements that dictate its language syntax and format. All language commands in database management systems or databases are executed through specialized SQL command line interfaces or CLIs. The significant elements of SQL include Clauses which are components of SQL statements or queries. Expressions which make scalar values or tables and which usually consist of rows and columns of data. Predicates which specify conditions and are used to limit statement effects or queries. Queries which are actions to retrieve data based on specific criteria. Statements which are used to control transactions perform diagnostics make connections and adjust program flow or sessions. Very broadly when a database system uses SQL SQL statements send queries from a client program or server where data is stored. The server then processes SQL statements and gives replies to the client program or terminal. In this way SQL lets users execute many data manipulation operations quickly and efficiently using direct data inputs. Common SQL commands To better understand SQL and how it works it helps to understand some of the most common SQL commands. Here are just a few examples Create database a command used to create a database. Create table which is used to create tables. Select which is used either find or extract data from a database. Update which allows users to edit or make adjustments to data. Delete which enables users to delete some data. Drop which is used to remove databases or tables. Insert into which lets users insert fresh data into a database. SQL is such a comprehensive and versatile language that it also includes many more complex commands. As a data control language data analysts spend a lot of time learning the ins and outs of its database tables database objects relational models and data types. How does SQL work While there are different versions or frameworks for SQL the most common framework used is MySQL. MySQL is an opensource version of this programming language that facilitates the primary role of SQL enabling organizations to manage their backend data and web applications quickly. For instance companies like Instagram Facebook and more use SQL for data processing and backend data storage. So how does this all work When a user or programmer writes an SQL query it is written and run or parsed according to the official terminology and a query optimizer then processes it. Once the SQL query reaches the SQL server it goes through three distinct phases parsing binding and optimization. Put very simply Parsing is an SQL process that checks syntax for the query. Binding is an SQL process that checks the querys semantics or details. Optimization is an SQL process that generates the query execution plan or that carries out the requested command. If you want to know more about this you can take some SQL courses for your personal knowledge or your company. Related How to Become Master of Your Data with Microsoft SQL For Only 40 Many of these courses are reasonably affordable so it doesnt take much to learn SQL even for beginners to data science or SQL syntax. The SQL compiling process explained Heres a breakdown of the SQL compiling process in a little more detail. First parsing takes place. This tokenizes the SQL statement into different words checking them for verbiage clauses and specific symbols. Next the SQL server will check semantics. This means it validates the statement to ensure it is legitimate or understandable. In other words the server ensures that the SQL query makes sense. Many servers also provide that the data the user requests exists and the user has the appropriate privileges to execute a specific query. Then comes binding. The SQL server makes a query plan for the received statement during this stage. This forms a binary representation of any steps needed to carry out the query or statement in byte code. This renders the compilation as a commandline shell a program that can read SQL statements and send them to a database server for optimization and execution. At this stage the SQL server optimizes the query plan and chooses the ideal algorithms for searching or storing data. Depending on the server or program it may use a feature called query optimization or a relational engine. Last the server executes the SQL statement by running the query plan depending on what exactly needs to be done. Related Learn How to Manage Data Like a Pro with This SQL Course Summary SQL is one of the most crucial programming languages and businesses use it daily. Now you know how SQL works why its essential and how to leverage it for your advantage a critical skill whether you need to build a business website or want to get into the IT sector. Entrepreneur Editors Picks These Are the Hottest Franchises to Watch in 2023 This One Question Will Make You a Better Thinker. Are You Asking It Already How the CEO of Zoom Room Is Leading the Way in Dog Training and Education Before Pressing the Layoff Button Leaders Need to Ask Themselves 1 Question Then Do These 3 Things 3 Simple Strategies for Coping With Overwork Pressure Taco Bell Uses This LittleKnown Secret to Stay on Top Year After Year Once a Skeptic Elon Musk Now Embraces This Divisive Workplace Policy and You Should Too.
The ChatGPT bot is causing panic now – but it’ll soon be as mundane a tool as Excel | John Naughton,A new AI-assisted chatbot that can generate eerily fluent prose is only the latest in a long series of useful tech accessoriesSo the ChatGPT language processing model burst upon an astonished world and the air was rent by squeals of delight and cries of outra…,2023-01-07T16:00:23Z,https://www.theguardian.com/commentisfree/2023/jan/07/chatgpt-bot-excel-ai-chatbot-tech,So the ChatGPT language processing model burst upon an astonished world and the air was rent by squeals of delight and cries of outrage or lamentation. The delighted ones were those transfixed by discovering that a machine could apparently carry out a written commission competently. The outrage was triggered by fears of redundancy on the part of people whose employment requires the ability to write workmanlike prose. And the lamentations came from earnest folks many of them teachers at various levels whose day jobs involve grading essays hitherto written by students. So far so predictable. If we know anything from history it is that we generally overestimate the shortterm impact of new communication technologies while grossly underestimating their longterm implications. So it was with print movies broadcast radio and television and the internet. And I suspect we have just jumped on to the same cognitive merrygoround. Before pressing the panic button though its worth examining the nature of the beast. Its what the machinelearning crowd call a large language model LLM that has been augmented with a conversational interface. The underlying model has been trained on hundreds of terabytes of text most of it probably scraped from the web so you could say that it has read or at any rate ingested almost everything that has ever been published online. As a result ChatGPT is pretty adept at mimicking human language a facility that has encouraged many of its users to anthropomorphism ie viewing the system as more humanlike than machinelike. Hence the aforementioned squeals of delight and also the odd misguided user apparently believing that the machine is in some way sentient. The bestknown antidote to this tendency to anthropomorphise systems such as ChatGPT is Talking About Large Language Models a recent paper by the distinguished AI scholar Murray Shanahan available on arXiv. In it he explains that LLMs are mathematical models of the statistical distribution of tokens words parts of words or individual characters including punctuation marks in a vast corpus of humangenerated text. So if you give the model a prompt such as The first person to walk on the moon was... and it responds with Neil Armstrong thats not because the model knows anything about the moon or the Apollo mission but because we are actually asking it the following question Given the statistical distribution of words in the vast public corpus of English text what words are most likely to follow the sequence The first person to walk on the moon was A good reply to this question is Neil Armstrong. So whats going on is nexttoken prediction which happens to be what many of the tasks that we associate with human intelligence also involve. This may explain why so many people are so impressed by the performance of ChatGPT. Its turning out to be useful in lots of applications summarising long articles for example or producing a first draft of a presentation that can then be tweaked. One of its more unexpected capabilities is as a tool for helping to write computer code. Dan Shipper an experienced software guy reports that he spent Christmas experimenting with it as a programming assistant concluding that Its incredibly good at helping you get started in a new project. It takes all of the research and thinking and looking things up and eliminates it In 5 minutes you can have the stub of something working that previously wouldve taken a few hours to get up and running. His caveat though was that you had to know about programming first. That seems to me to be the beginning of wisdom about ChatGPT at best its an assistant a tool that augments human capabilities. And its here to stay. In that sense it reminds me oddly enough of spreadsheet software which struck the business world like a thunderbolt in 1979 when Dan Bricklin and Bob Frankston wrote VisiCalc the first spreadsheet program for the Apple II computer which was then sold mainly in hobbyist stores. One day Steve Jobs and Steve Wozniak woke up to the realisation that many of the people buying their computer did not have beards and ponytails but wore suits. And that software sells hardware not the other way round. The news was not lost on IBM and prompted the company to create the PC and Mitch Kapor to write the Lotus 123 spreadsheet program for it. Eventually Microsoft wrote its own version and called it Excel which now runs on every machine in every office in the developed world. It went from being an intriguing but useful augmentation of human capabilities to being a mundane accessory not to mention the reason why Kat Norton aka Miss Excel allegedly pulls in sixfigure sums a day from teaching Excel tricks on TikTok. The odds are that someone somewhere is planning to do that with ChatGPT. And using the bot to write the scripts. What Ive been reading Triple threat The Third Magic is a meditation by Noah Smith on history science and AI. Dont look backNostalgia for Decline in Deconvergent Britain is Adam Toozes long blogpost on the longer history of British economic decline. Inequalitys impactsWho Broke American Democracy is an insightful essay on the Project Syndicate site by Nobel laureate Angus Deaton.
Citizen's New Smartwatch AI Helps You Maximize Your Potential,"At CES 2023, Citizen unveiled its latest range of CZ Smart smartwatches. Designed to function with its new proprietary YouQ app, the watches were developed using IBM Watson Studio and NASA technology.The built-in AI ""self-care advisor"" serves to help users ""m…",2023-01-05T08:03:25Z,https://hypebeast.com/2023/1/citizen-cz-smart-watch-ai-self-care-advisor-release-ces-2023-info,Citizens New Smartwatch AI Helps You Maximize Your Potential Coming in 44mm sport and 41 casual models. At CES 2023 Citizen unveiled its latest range of CZ Smart smartwatches. Designed to function with its new proprietary YouQ app the watches were developed using IBM Watson Studio and NASA technology. The builtin AI selfcare advisor serves to help users maximize daily potential by learning ones chronotype preferred timing of sleep and wake through IBM Watsons neural networks. The seven to tenday monitoring period processes sleep data and info from customdesigned alert monitor tests a consumer version of NASAs PVT test created at the Ames Research Center Fatigue Countermeasures Laboratory. The data is then used to create a dynamic recognition model on the YouQ app to recommend Power Fixes that will help reduce fatigue and improve alertness. The secondgeneration Citizen CZ Smart watches come in 44mm sport and 41 casual models which can be outfitted with mesh bracelets links or silicone straps. The watches feature 1. 3inch AMOLED displays and Snapdragon Wear 4100 processors with 8GB of storage running Wear OS. With over 24 hours of battery life and fast charging the watches are outfitted with a gyroscope altimeter barometer accelerometer heart rate sensor and SP02 ambient light sensor. Compatible with both Apple iPhone and Android devices the watches come loaded with the YouQ wellness app Strava Spotify YouTube Music and Amazon Alexa. Priced between 350 and 375 USD the secondgeneration CZ Smart watches will be available via Citizen later this March. In case you missed it OneThirds freshness scanners calculate if fruits are ripe.
Microsoft will have to buy OpenAI in 2023,The power of platform network effects,2023-01-09T05:37:21Z,https://www.thoughtfulbits.me/p/microsoft-will-have-to-buy-openai,Microsoft will have to buy OpenAI in 2023 The power of platform network effects The short version Its a simple dilemma AI benefits from network effects. If Microsoft integrates OpenAI into its products it will increase the capabilities of OpenAImore data training and apps. As AI features become musthave features Microsofts business success will increasingly depend on OpenAI. In the short run AI features would give Microsoft a competitive edge but in the long run those features would shift shareholder value creation to OpenAI away from Microsoft. Microsoft will have no choice but to acquire OpenAI or rights equivalent to ownership. The long version Following up on my earlier post it has now been publicly reported that Microsoft has been working with OpenAI about integrating their AI technology into Microsoft Office and into Bing httpsappleinsider. comarticles230107microsoftplansaddingopenaichatbottechtoproductivityapps httpswww. theguardian. comtechnology2023jan05microsoftchatgptbingsearchengine. If done well this would create immense value for Microsofts customers. Ive already talked about how extensively I use AI myself and how I no longer use Microsoft Word as its nowhere near as efficient as writing with AI assistance. These assistancetype features will rapidly become essential for any competitive product. However integrating AI from OpenAI creates a fundamental business challenge for Microsoft. Typing printing document sharing and so forththe base features of Microsofts productivity toolsare effectively commodity features now. Google Docs Apple PagesKeynoteMail and so on are perfectly fine substitutes for Microsoft Office. But those products have yet to demonstrate features that dramatically shift market share away from Microsoft Office. Google arguably has come the closest but even then many Google users still maintain licenses to Microsoft Office. AI could change thatand change it fast. How fast it changes though is orthogonal to the business dilemma. If AI features become the competitive battleground for knowledge worker productivity tools Microsoft will have to have those features plain and simple. But if it gets those features from a thirdparty company OpenAI that shifts value creation away from Microsoft and to OpenAI. This value transfer problem is seen over and over in business. Ironically Microsoft itself benefited from it with their original MSDOS deal with IBM for the IBM PC httpsthisdayintechhistory. com1106ibmsignsadealwiththedevil. With that deal for the MSDOS operating system Microsoft captured the network effects and value creation for owning the underlying software platform. The IBM PC business became just one of many hardware manufacturers. source httpscommons. wikimedia. orgwikiFileOriginalIBMPC285133233471129. jpg AI similarly has powerful network effects. OpenAIs current business model is genius. By allowing free usage of chatGPT they are getting millions of free employees all actively and eagerly providing more data and more training to the system. At the most fundamental level AI benefits from more data and training. Its one of the reasons why Google has been able to maintain a substantial lead in search until maybe now despite the billions of dollars Microsoft has invested in Bing. Google simply had more dataand specifically more usage data. Google had more queries than Bing and more clicks indicating what websites are better results than Bing. It was such a formidable advantage to overcome that Microsoft eventually resorted to outright just copying Google httpswww. wired. com201102bingcopiesgoogle. More importantly OpenAI is at its core a software platform for applications. They have done a great job creating easytouse and capable APIs for other companies to leverage in their products. Im using those APIs myself extensivelymore on that in upcoming posts. Being the fundamental AI platform will only further accelerate the network effect more apps on OpenAI means more data more training and better results for OpenAI which in turn will lead to more apps on the platform. Positive feedback loops are exceptionalexceptional for the loop owners and exceptionally difficult for others to disrupt. Microsoft knows this firsthand with Bing and recall that Satya Nadella Microsofts CEO was the executive in charge of Bing for many years. Even if competing AI platforms emerge and they will those competitive platforms must be exceptionally inventive to overcome the early lead OpenAI is achieving. Microsoft has outstanding inhouse AI talent and has invested in AI for decades. However all that talent does not change the network effect that OpenAI is enjoying now. So why has Microsoft yet to announce an acquisition They may well be already in discussions. Either way the internal debate is likely discussing the following dilemma if Microsoft buys OpenAI too soon it could open up the door for strengthening the competition. Its one thing for companies worldwide to rely on an independent thirdparty platform but those companies might pause before being solely dependent on Microsoft and want a viable alternative. We see a similar dynamic with Amazon and Shopify. If you are an ecommerce vendor there are a lot of advantages to being on the Amazon platform. But Amazon is aggressivedo you really want to build on Amazon if Amazon is going to learn from you and build competing products to your own Maybe its better to use Shopify and not have the competition from your platform provider httpswww. cnbc. com20220706amazoninvestigatedbyukwatchdogoveritsmarketplacepractices. html. Additionally there are countless examples of companies acquiring disruptive technologies too soonYahoos acquisition of Overture in 2003 is a particularly noteworthy example. Even though Overture at the time was dominant it did not stop Google from rapidly overtaking the search market httpswww. wired. com200702yahoo3. Even though Overture had by far the early lead Google learned from Overture and effectively built the better mousetrap. Conversely from a shareholder value creation perspective Microsoft would have a tough time justifying having their knowledge worker business depend on OpenAI as an external independent company. Microsoft is supposed to generate value for its shareholders not OpenAI shareholders The more OpenAIs AI technology becomes crucial to Microsofts business the more pressure there will be for Microsoft to acquire OpenAI. There would also be legal and regulatory reasons for Microsoft to acquire OpenAI. Many exciting use cases for AI in Microsoft Office involve analyzing or creating data e. g. writing assistance for documents or analyzing a spreadsheetdata that could be proprietary and confidential to a company. That customer data would need to be kept separate and isolated between customers in some fashion. Imagine an Airbus executive writing a business plan for a new airliner only to have the AI make suggestions that include the details of Boeings new airplane This privacy and rights problem for AI is a deep topic. For this note Ill simply comment that those challenges need both technological solutions as well as business solutions. Lets say a company is using OpenAIpowered Microsoft Office but sensitive PII customer data is sent to OpenAI in a way that violates European GDPR regulations. Who is liable How would that be handled Sure all sorts of contracts indemnifications and so forth could be crafted but at some point it would be much easier for Microsoft to simply own OpenAI. A subtle nuance here is Microsofts onebilliondollar investment into OpenAI httpsopenai. comblogmicrosoft. Microsoft has a highly talented business development team. Likely the OpenAI investment came along with contractual terms that would facilitate an acquisition or potentially make an acquisition by others more difficult. Those terms may enable Microsoft to postpone deciding on an acquisition. But at the end of the day if AI becomes fundamental to Microsofts business from a shareholder perspective they will have to buy. Of course for the completeness of the discussion Microsoft could construct a partnership agreement that effectively gives them the same value as an outright acquisition. It would be complex but conceptually possible. Such an agreement would need to result in Microsoft having rights similar to those they would enjoy as owners e. g. Google couldnt buy OpenAI and shut Microsoft off. Bottom line I am quite sure this discussion is happening now inside Microsoft. As an outside observer I think it would be a smart move for Microsoft. But regardless of the outcome its going to be an exciting year ThoughtfulBits Ideas that Matter is a readersupported publication. To receive new posts and support my work consider becoming a free or paid subscriber.
Is It Too Late to Buy IBM Stock?,"Against all odds, IBM was the top big tech stock in 2022. Have investors missed the boat?",2022-12-30T12:40:00Z,https://www.fool.com/investing/2022/12/30/is-it-too-late-to-buy-ibm-stock/,Who had International Business Machines IBM 0. 23 outperforming all other largecap tech stocks on their 2022 bingo cards While tech stocks have generally been a disaster this year centuryold IBM has delivered a marketbeating performance for investors. From its pandemic low in early 2020 IBM stock is now up more than 50. The stock has been slowly gaining ground since bottoming out while other tech stocks have soared only to crash spectacularly wiping out pandemicera gains. While IBM has been a top performer this year investors can still buy the stock at a reasonable price. A turnaround thats finally gaining traction IBM has been working on transforming itself for nearly a decade. The company has ditched legacy businesses where it had no meaningful competitive advantages invested in cloud computing doled out 34 billion for software company Red Hat to strengthen its cloud computing hand and spun off its massive managed infrastructureservices business. IBM is much smaller than it once was but the companys product portfolio is now skewed toward highervalue hardware software and services. More than 70 of IBMs revenue now comes from software and consulting and hybrid cloudrelated revenue has reached 22. 2 billion over the past 12 months. IBMs mainframe business continues to chug along with whole industries dependent on the hulking systems. Around 90 of the worlds top 50 banks still run on IBM mainframes. Based on IBMs latest results the company may have finally found its groove. Revenue jumped 15 year over year in the third quarter adjusted for currency and the company is on track to deliver solid revenue growth this year along with around 10 billion of free cash flow. While a recession next year may create some headwinds for IBM the company should otherwise be able to deliver sustainable revenue growth from here on out. A reasonable valuation With a market capitalization of about 127 billion IBM stock trades for less than 13 times its freecashflow guidance. Based on the average analyst estimate for 2023 earnings the stock trades at a pricetoearnings ratio below 15. IBM is aiming to deliver midsingledigit revenue growth and highsingledigit freecashflow growth through 2024. Much of that growth will be driven by software and consulting while the hardware business should remain roughly flat adjusted for product cycles. Because IBM is shifting toward software theres plenty of room for margin expansion over time. One thing worth noting is that IBM has a significant amount of debt. Total corporate debt which excludes debt tied to the financing businesses stood at 39. 7 billion at the end of the third quarter. The company essentially stopped buying back its own shares following the Red Hat deal and its dividend already eats up around 6 billion annually. In other words investors shouldnt expect a significant increase in the dividend or a restart of the sharebuyback program until free cash flow rises. Speaking of the dividend IBM offers a generous one. A quarterly pershare payment of 1. 65 works out to a dividend yield of about 4. 7. The dividend has been increasing very slowly since 2020 and that trend will likely continue for now. Still IBMs dividend yield is more than double that of the SP 500s. IBM stock isnt going to 10x anytime soon but the company seems to have finally positioned itself to grow revenue and free cash flow consistently as it taps into demand for hybridcloud computing. With IBMs solid dividend and attractive valuation 2023 may be an even better year for the companys stock.
North American semiconductor industry will prevent 'over-reliance' on Asia: Trudeau - National | Globalnews.ca - Global News,"<ol><li>North American semiconductor industry will prevent 'over-reliance' on Asia: Trudeau - National | Globalnews.ca  Global News
</li><li>López Obrador tells Trudeau he'll meet with Canadian power companies over dispute  The Globe and Mail
</li><li>Prime…",2023-01-11T23:53:53Z,https://globalnews.ca/news/9403453/trudeau-three-amigos-semiconductors-north-america/,Prime Minister Justin Trudeau said Wednesday he will push to ensure Canada plays a vital role in North America becoming a reliable supplier of semiconductors to the global economy yet admitted that role is still somewhat to be determined. Trudeau made the comments following the North American Leaders Summit with U. S. President Joe Biden and Mexican President Andres Manuel Lopez Obrador in Mexico City where the socalled Three Amigos agreed to boost semiconductor output and investment in the continent to compete with Asia which has dominated the industry. The world has realized that an overreliance on any one region for semiconductors will have dire consequences on the economy that were building for the future he said. Canada has a significant role to play in the semiconductor industry. What exactly that role is is still somewhat to be determined. Read more Canada U. S. Mexico pledge to tighten economic ties boost domestic production Read next Here are North Americas most punctual airlines. No Canadian carriers made the list He pointed to the semiconductor assembly plant in Bromont Que. one of the largest such facilities in North America and a key supplier for tech giants like IBM as one area where Canada can contribute. The federal governments new critical minerals strategy unveiled last month is designed to supply the resources needed to build increasingly important semiconductors that are used in everything from telecoms to electric vehicles and defence. Our focus is on making sure that Canada and Canadians are a part of the semiconductor ecosystem Trudeau said. He added that Canadas contributions to the North American auto industry not just building vehicles but also various parts that are assembled elsewhere provides an economic model that can be replicated for semiconductors. COVID19fuelled lockdowns in semiconductor manufacturing centres like China and Taiwan led to a global shortage of microchips that is still being felt in the automotive and electronics industries among others. The pandemic along with Russias war in Ukraine that impacted energy supplies for Europe has led to Canada and other Western countries looking elsewhere around the world for strategic partnerships to avoid overly relying on single countries or regions for crucial industries particularly disruptive nations like Russia and China. The North American strategy agreed to this week will see a semiconductor forum organized for early 2023 to increase investment across all three countries. Trudeau said conversations being had with North American partners and elsewhere regarding critical minerals and semiconductors are geared towards agreements that are still months and even years away with nothing concrete having been agreed to during his time in Mexico City. The reception that weve seen from Canadas critical minerals strategy has been overwhelmingly positive he said. When we have great announcements to make we make them. Mexicos hopes of benefiting from the push to boost semiconductor output have been undermined by an ongoing dispute over Lopez Obradors nationalist energy policies with Washington and Ottawa starting formal dispute settlement proceedings in July. The spat which centres on Mexicos efforts to give priority to its cashstrapped staterun energy companies at the expense of private foreign investors was being closely watched at the summit. Trudeau said the issue was discussed and that Lopez Obrador was receptive to his and Bidens concerns. Read more Tensions between U. S. Mexico on full display as Three Amigos summit opens Read next Kanye West reportedly marries Yeezy designer Bianca Censori Trudeau dismissed the idea that Lopez Obrador is a trade skeptic saying the Mexican president was extremely positive about Canadian trade and investment in Mexican energy. Earlier Wednesday following a bilateral meeting with Trudeau Lopez Obrador pointed to TC Energys investment in the 4. 5 billion Southeast Gateway Pipeline that would bring natural gas to southeastern Mexico as a significant example of successful Canadian investment. The pipeline is part of an overall strategy for Lopez Obradors government to lure foreign investment to its south from the northern frontier region where it clusters for easy access to the United States. On the more contentious issue of electricity where Mexico is also being accused of limiting foreignbuilt plants Lopez Obrador said he told Trudeau that he would meet with Canadian companies that have complaints with his administrations policies. The CanadaU. S. Mexico free trade agreement known as CUSMA prohibits favouring domestic companies over those from other member states. Read more Canada and Mexico win trade dispute with U. S. on rulesoforigin for auto goods Read next Lisa Marie Presley dies at 54 after suffering cardiac arrest family says Trudeau said both Lopez Obrador and Biden who has pushed a Buy American economic strategy that has prompted concerns about trade relations with Canada are simply looking out for their own workers as Canada does adding theres no contradiction between that approach and working with allies. Thats what this particular gathering has been entirely focused on understanding that the three of us working together are an extraordinarily competitive continent that can take on the world he said. Trudeau will head right from the Mexico City summit to meeting with another key ally Japanese Prime Minister Fumio Kishida in Ottawa on Thursday. Japan is similarly trying to pivot away from a reliance on China and Russia for electricity and food echoing comments made by Trudeau and other leaders in recent weeks. There is a risk involved in relying excessively upon a single country economically and we now fear that risk more intensely than ever Japanese trade minister Yasutoshi Nishimura told a Washingtonbased think tank last week. Canadas recent IndoPacific strategy identifies the region including Japan and South Korea as another opportunity for key investment and trade corridors in order to mitigate Chinas dominance. with files from the Canadian Press and Reuters
Motorola’s ThinkPhone is the coolest phone of CES 2023 — but you can’t buy it,"This is the ThinkPhone by Motorola, and it's one of the most interesting, best-specced Moto phones we've seen. It's a shame Motorola won't sell it to you.",2023-01-05T16:00:17Z,https://www.digitaltrends.com/mobile/thinkphone-by-motorola-news-announce-ces-2023/,This is the ThinkPhone by Motorola. It has great specs and a sweetlooking highly nostalgic design that taps into the classic IBM ThinkPad craze of the 1990s. Its a Motorola phone youll actually want to buy possibly without thinking twice. If youve followed Motorolas other smartphones as of late youll know thats not something that happens very often. Unfortunately just when Motorola made an eyecatching tantalizing Its all about business Its not that the ThinkPhone is only available in China or that its a super limited edition or that it costs the same as a rather nice house. Its because the ThinkPhone is a business phone and it heads up Motos push into the B2B market meaning it wont be available at your local carriers store or unlocked online. Its a direct play for companies that are already using or considering a fleet of ThinkPad When asked Motorola said that although it understands consumers would benefit from the phones functionality it has no specific plans to make it a consumer product. What is it youre missing out on The most striking aspect is the cool ThinkPadinspired design. The phones back is made from carbon fiber with an aluminum chassis and Gorilla Glass Victus over the screen. It has been put through toughness tests to meet the military standard for MILSTD810H certification plus it has an IP68 water and dustresistance rating. This is a tough It feels sturdy but strikes a balance of not being bulky or unnecessarily heavy. In the hand it feels just like any other bigscreen phone with a large battery inside. The ThinkPhone by Motorola branding is set at an angle on the back of the device recalling the classic IBM ThinkPad style plus theres a red button on high on the left side again harking back to the red navigation button on a ThinkPad laptop. On this phone its a shortcut to Motorolas Ready For suite of connectivity and productivity tools and can also be assigned to an app of your choice. You can have the button perform a different pair of functions depending on whether youre in a personal or work profile too which is nice. The Ready For suite contains features to improve how you use your phone and PC together quickly share files stream apps between devices creating a hotspot and using a shared clipboard. You can even fire up the phones camera and use it as a webcam for your connected laptop. The right software and specs The ThinkPhone runs Android 13 and Motorola promises three years of major Android version updates along with four years of security updates. It may not quite rival Samsung and OnePlus but it matches Googles own update commitment and is also far more comprehensive than some consumer Motorola phones. The phone incorporates Motorolas ThinkShield security platform and a new Think 2 Think dedicated security chip. The overall specs are great. The ThinkPhone has the Qualcomm Snapdragon 8 Gen 1 processor inside with 8GB of Plus theres a 5000mAh battery with wireless charging and fast charging. A 68watt fast charger comes in the box and has enough power to run a highpowered laptop so you only need to carry one brick around when out and about. The camera system has a 50megapixel main camera with optical image stabilization OIS a 13MP wideangle a depth camera and a 32MP selfie camera. We didnt get to use the cameras in our limited handson time but Motorolas been able to deliver fine camera performance with a setup like this so were not too concerned. If theres one gripe here its that the design of the camera pod clashes rather oddly with the slick carbon fiber back it looks like its lifted straight from another phone and it probably is. Nostalgia but not for you and me If youre wondering how Motorola is allowed to lean so heavily on the ThinkPad angle its because Motorola Mobility is owned by Lenovo which also owns the ThinkPad name having purchased IBMs personal computer business in 2005. Motorola itself is also no stranger to creating nostalgic products having released several versions of a folding Razr influenced by the classic Razr flip phone. And Lenovo still leans heavily on the ThinkPad name for its topend and often enterprisefocused But youll have to look at the Razr which is also quite difficult to buy if youre in the U. S. if youre truly focused on getting some kind of nostalgic fix. The ThinkPhone by Motorola will be released in January 2023 in the U. S Europe Latin America the Middle East and parts of Asia but will only be available to businesses. And its a shame as it looks to be one of the most interesting most comprehensively specified smartphones from Motorola in years. Theres more to get excited about here than yet another Motorola One or Moto G to be frank. Editors Recommendations Samsung Galaxy S23 release date specs price rumors and news I compared the camera on the worst iPhone with the cheapest iPhone How the Kindle Scribe quietly became my favorite gadget of 2022 Underdisplay Face ID on the iPhone 16 Pro raises 3 big questions 5 things the iPhone has to change in 2023 before I ditch Android
How Novell Netware lost the battle against Windows NT (2013),"In a parallel universe, the LAN king would have crushed Microsoft",2022-12-28T14:27:05Z,https://www.theregister.com/2013/07/16/netware_4_anniversary/,How the clammy claws of Novell NetWare were torn from todays networks In a parallel universe the LAN king would have crushed Microsoft Anniversary Before the internet local area networks were the big thing. A company called Novell was the first to exploit the trend for connecting systems ultimately becoming the LAN king with its NetWare server operating system. There were alternatives to Novell and NetWare in the 1990s 3Coms 3Share for example but such was its appeal that Novells share of the LAN market topped 63 per cent at its high point. Such scale cannot go unnoticed and it caught the interest of Microsoft then just a PC operating system maker with Office apps. Bill Gates and his team quickly realised they had to build their own server operating system if the were really serious about growing their new company. In April 1993 Novell released NetWare 4. 0 the version that really made the company and broke it. Twenty years on its not Novell or NetWare we talk about on the server its Microsoft and Windows Server and Linux. NDS Killer feature or SMB killjoy NetWare 4 was a major upgrade a native Intel 80386 NOS Network Operating System like NetWare 3 before it but now with builtin TCPIP and better support for applications running on the server. The big difference though was NDS NetWare Directory Services a distributed network directory. This was a killer feature for larger multisite or even multiserver networks but it was also a killjoy for small business network admins. The first version of NetWare was a resolutely singleserver product it didnt even allow multiple servers on a single network. NetWare 1 originally ran on Novells proprietary 68000based server and used a proprietary connection SNet but it offered a compelling advantage over the other early networking systems file sharing as opposed to disk sharing. Rather than splitting up an expensive hard disk into multiple separate segments one per workstation NetWare allowed all workstation to access individual files on a single shared volume. At the time this wasnt an obvious idea but it was soon legitimised by the otherwiseunsuccessful IBM PC LAN. Using a file server meant that PCs could share data with one another for example permitting the first networkaware PC program of any kind Novells network game SNIPES. As the networking market grew Novell ported NetWare to the IBM PCXT the upmarket model with a hard disk as standard and opened it up to support a dozen other networking systems including Corvus Omninet Datapoint ARCnet and 3Coms new and very expensive Ethernet. NetWare 2 was a radical rewrite and one of the first native OSes for Intels then new 16bit CPU the 80286. Member when... Intels 16bit x86 microprocessor. Image via CPU Collection of Konstantin Lanzet licensed under Creative Commons NetWare 2 supported 16MB of server memory and even able to multitask with a copy of MSDOS for nondedicated operation. However it was a pain to install and configure it was supplied on more than 20 floppy discs and requiring Novells proprietary kernel to be relinked for any configuration change a lengthy session of diskaerobics. NetWare 3 was the biggest rewrite NetWare would ever get. The OS was modularised with a kernel and separate NetWare Loadable Modules NLMs providing additional functionality. This meant that your NetWare file and print server could also now handle email for instance. NetWare 3 also offered System Fault Tolerance Level III the ability to mirror a pair of NetWare servers in a sharednothing cluster. NetWare 3 also removed an obscure ability that NetWare 2 had the significance of which would only appear much later. NetWare 2 could cold boot the OS was able to load itself from a bootable NetWare system volume. NetWare 3 was an MSDOS executable your server booted from a DOS partition or even a DOS floppy and at the end of AUTOEXEC. BAT you ran SERVER. EXE. DOS remained in RAM unless removed and was needed if you wanted to access files on floppy diskette. NetWare was now a serious product ready for prime time but its authentication system remained a weakness. NetWares Bindery Services comprised a standalone authentication database meaning that users had to log on to multiple servers separately and admins had to maintain separate user lists on every server. NetWare Name Services alleviated this as the single database could be extended across multiple servers but this rapidly became unmanageable for large organisations with multiple sites particularly if these were in different countries. This was the problem that NetWare 4 was designed to solve. NDS was a distributed network directory based on the CCITT X. 500 standard. A single directory tree would span your entire organisation with branches containing servers workstations users groups and any other entity whose security you needed to control. Banyans VINES had been offering this for years with StreetTalk but it was a specialist product whereas NetWare was the leading PC server OS. What NDS offered was brilliant it was vastly ahead of Microsofts domain security model as used in OS2 LAN Manager and Windows NT Server 3. 1 also released in 1993.
I'm Passing on Intel Because IBM and Texas Instruments Are Better,"Intel's high yield is tempting, but I just can't get myself to pull the trigger when I compare it to IBM and Texas Instruments.",2022-12-23T10:15:00Z,https://www.fool.com/investing/2022/12/23/passing-on-intel-because-ibm-texas-instruments/,Im a dividend investor so an outoffavor stock like Intel INTC 0. 48 with its historically high yield is something Im going to take a look at. The company has some attractive features. But a deeper dive suggests the risks outweigh the benefits especially when I compare the chip giant to my investments in International Business Machines IBM 0. 23 and Texas Instruments TXN 0. 11. Here are two big reasons why Im taking a pass on Intel. 1. A high yield on its own isnt enough The big thing that attracted me to Intel was the stocks current 5. 4 dividend yield. Thats not only large on an absolute level but its also near the highest levels in the companys history suggesting the stock is relatively cheap today. That combination is easily enough to get me to take a closer look at Intel right now. One warning sign for me here however is that the dividend hasnt been increased annually for even 10 consecutive years. By comparison IBM has increased its dividend annually for over 25 years. IBMs yield meanwhile is an attractive 4. 7. And while the yield isnt near alltime highs it is still fairly generous historically speaking. And theres the fact that IBM has an over 100year history that includes several major business transformations one of which has just recently been completed with the companys purchase of RedHat. In fact a long period of declining sales appears to have turned around. While IBM is hardly perfect it has proven that it can adjust with the times. One of the reasons why Intel is in the Wall Street doghouse today is that it hasnt actually proven it can do that. When smartphones became more important it missed the opportunity and its efforts in autonomous driving havent been inspiring it just spun off a piece of Mobileye which I dont think it would have done if this push into the autonomous driving sector was a huge success. Meanwhile it has recently fallen behind CPU competitors because it has faced delays with new technology. Change takes time and it is likely that the company will muddle through but Id rather stick with IBM which has a similar yield and a better business history. 2. Not enough diversity On the other side of the coin looking specifically at chip stocks Intel has one main product that gets used in two main end markets. Basically from my simplistic point of view as a nontech investor it makes the brains of a computer the CPU. As mobile devices have become increasingly important demand for desktop computers has largely waned. Intel appears to have gotten lucky with the server market basically just a variation on a computer taking off to supply the data centers that support mobile demand. In some ways its a onetrick pony. Texas Instruments meanwhile makes far simpler microchips that get used in thousands of products. To put a number on that this chipmaker has around 80000 products that it sells to more than 100000 customers. The chips it makes are very similar to each other but thats kind of the point. These are simple commodity chips that are somewhat fungible making them easier to sell into the market. I believe strongly in diversification for my portfolio and I tend to favor companies that have diversification in their businesses too. Meanwhile Texas Instruments has increased its dividend annually for 19 consecutive years. And its 2. 9 dividend yield is toward the high end of its historical range suggesting it is relatively cheap. Like Intel Texas Instruments is focusing on capital investments right now but the stakes arent nearly as high. Intel needs to upgrade its tech or risk falling further behind its peers Texas Instruments is really just trying to prepare ahead of time for the increased demand it sees down the road. Thats a much stronger position to be in. Tech confuses me but... Ill happily admit that Im not a technology genius but I dont think you need to be to see the bigger picture trends at these three companies. And when you add up the pros and cons Intel just doesnt seem as attractive as similarly highyield IBM or Texas Instruments in the chip sphere. I reserve the right to change my mind but right now Im passing on Intel because it doesnt stack up to the other tech names I own.
Apple finally lets us know what was in those AirTag firmware updates,"Over the past couple of months, Apple has released two firmware updates for the AirTag that had no release notes. Now Apple has finally told us what actually happened when our trackers updated.




In a support document, Apple detailed the changes in the two…",2022-12-20T13:51:38Z,https://www.macworld.com/article/1440221/airtag-firmware-updates-release-notes.html,Over the past couple of months Apple has released two firmware updates for the AirTag that had no release notes. Now Apple has finally told us what actually happened when our trackers updated. In a support document Apple detailed the changes in the two latest firmware updates sent in midNovember and midDecember. Here are the changes. AirTag Firmware Update 2. 0. 36 Resolves an issue with the accelerometer not activating in certain scenarios. AirTag Firmware Update 2. 0. 24 Enables Precision Finding to help locate an unknown AirTag detected moving with you. If your iPhone is awake a notification alerts you when an AirTag thats separated from its owner is traveling with you and emitting a sound to indicate it has been moved. These arent major changes but its clear that Apple will add features to the AirTag from time to time. For example the previous firmware update changed the unwanted tracking sound to better identify an unknown AirTag. We dont know if Apple will begin telling people whats in firmware updates at the time of release or continue to post the release notes weeks later.
Citizen’s new CZ smartwatch uses NASA and IBM Watson tech to gauge your energy levels,"Citizen announced a new smartwatch that brings the best of NASA and IBM Watson’s neural networks to help you gauge your wellness, fatigue and sleep patterns. Citizen CZ Smart works alongside the CZ Smart YouQ app for Android and iOS to help determine the wear…",2023-01-04T18:07:01Z,https://www.gsmarena.com/citizens_new_cz_smartwatch_uses_nasa_and_ibm_watson_tech_to_gauge_your_energy_levels-news-57077.php,Citizen announced a new smartwatch that brings the best of NASA and IBM Watsons neural networks to help you gauge your wellness fatigue and sleep patterns. Citizen CZ Smart works alongside the CZ Smart YouQ app for Android and iOS to help determine the wearers current energy score and forecast the remainder of the day. The watch also features brief gamified tests based on NASAs Psychomotor Vigilance Task Test PVT used by the space agency to determine the mental alertness of astronauts. The watch tracks user activity patterns and sleep schedules to develop Power Fixes to help the wearer stay alert and battle fatigue. Users will get timely suggestions on when to rest and the ideal time to workout. Citizen CZ Smart comes in 41mm and 44mm sizes with both models featuring a 1. 3 AMOLED touchscreen and boasts the Snapdragon Wear4100 chipset as well as 8GB onboard storage. You also get heart rate and SpO2 sensors as well as a gyroscope barometer and accelerometer. The watch boots Googles WearOS and comes with builtin Strava Spotify YouTube Music and Amazon Alexa apps. Citizen claims you can expect over 24 hours of battery life while a full charge should take around 40 minutes. Citizen CZ Smart will arrive in the US in March 2023. Pricing starts at 350. Sorry to get off topic but Im still surprised how gullible and immature people are. There are people hired to troll competitors there are insecure people scared of competition and others who are just too dull to accept change. A...
